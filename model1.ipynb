{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37364bittfgpucondac099bc5da9054a33945af826af1262b9",
   "display_name": "Python 3.7.3 64-bit ('tf-gpu': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "4b3fe4e430614ae3e36b8912aa67966595d32d796c9f5e46d3c96e8e35c078a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import numpy.fft as fft\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats, signal\n",
    "from numpy import save, load\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "source": [
    "### read dataset X and Y"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "84\n",
      "(14577, 208)\n",
      "76\n",
      "(28145, 208)\n",
      "36\n",
      "(52073, 208)\n",
      "38\n",
      "(76155, 208)\n",
      "40\n",
      "(83290, 208)\n",
      "50\n",
      "(101197, 208)\n",
      "52\n",
      "(110462, 208)\n"
     ]
    }
   ],
   "source": [
    "subject_id=1\n",
    "base_path = \"features_notwelch/\"\n",
    "# edf_file_names = sorted(glob.glob(os.path.join(base_path, \"data_chb01/*.npy\".format(subject_id))))\n",
    "# files=len(edf_file_names)\n",
    "X=load('features_notwelch/data_chb{:02d}/features_{}_00.npy'.format(subject_id,subject_id))\n",
    "y=load('features_notwelch/data_chb{:02d}/targets_{}_00.npy'.format(subject_id,subject_id))\n",
    "for subject_id in (1,3,6,7,8,10,14):\n",
    "    edf_file_names = sorted(glob.glob(os.path.join(base_path, \"data_chb{:02d}/*.npy\".format(subject_id))))\n",
    "    files=len(edf_file_names)\n",
    "    start=0\n",
    "    if subject_id==1:\n",
    "        start=1\n",
    "    for fileno in range(start, files//2):\n",
    "        X=np.concatenate((X, load('features_notwelch/data_chb{:02d}/features_{}_{:02d}.npy'.format(subject_id, subject_id, fileno))))\n",
    "        y=np.concatenate((y, load('features_notwelch/data_chb{:02d}/targets_{}_{:02d}.npy'.format(subject_id,subject_id, fileno))))\n",
    "    print(files)\n",
    "    print(X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "84\n",
      "(14577, 3)\n",
      "76\n",
      "(28145, 3)\n",
      "36\n",
      "(52073, 3)\n",
      "38\n",
      "(76155, 3)\n",
      "40\n",
      "(83290, 3)\n",
      "50\n",
      "(101197, 3)\n",
      "52\n",
      "(110462, 3)\n"
     ]
    }
   ],
   "source": [
    "subject_id=1\n",
    "base_path = \"sum_only/\"\n",
    "# edf_file_names = sorted(glob.glob(os.path.join(base_path, \"data_chb01/*.npy\".format(subject_id))))\n",
    "# files=len(edf_file_names)\n",
    "X_sum=load('sum_only/data_chb{:02d}/features_{}_00.npy'.format(subject_id,subject_id))\n",
    "y_sum=load('sum_only/data_chb{:02d}/targets_{}_00.npy'.format(subject_id,subject_id))\n",
    "for subject_id in (1,3,6,7,8,10,14):\n",
    "    edf_file_names = sorted(glob.glob(os.path.join(base_path, \"data_chb{:02d}/*.npy\".format(subject_id))))\n",
    "    files=len(edf_file_names)\n",
    "    start=0\n",
    "    if subject_id==1:\n",
    "        start=1\n",
    "    for fileno in range(start, files//2):\n",
    "        X_sum=np.concatenate((X_sum, load('sum_only/data_chb{:02d}/features_{}_{:02d}.npy'.format(subject_id, subject_id, fileno))))\n",
    "        y_sum=np.concatenate((y_sum, load('sum_only/data_chb{:02d}/targets_{}_{:02d}.npy'.format(subject_id,subject_id, fileno))))\n",
    "    print(files)\n",
    "    print(X_sum.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(110462, 208) (110462,)\n"
     ]
    }
   ],
   "source": [
    "X_shape, y_shape = X.shape, y.shape\n",
    "print(X_shape, y_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_columns():\n",
    "#     channel_order= {'FP1-F7':0, 'F7-T7':1, 'T7-P7':2, 'P7-O1':3, 'FP1-F3':4, 'F3-C3':5, 'C3-P3':6, 'P3-O1':7, 'FP2-F4':8, 'F4-C4':9, 'C4-P4':10, 'P4-O2':11, 'FP2-F8':12, 'F8-T8':13, 'T8-P8-0':14, 'P8-O2':15, 'FZ-CZ':16, 'CZ-PZ':17, 'P7-T7':18, 'T7-FT9':19, 'FT9-FT10':20, 'FT10-T8':21 ,'T8-P8-1':22 }\n",
    "#     col_names=[]\n",
    "#     for ch in channel_order:\n",
    "#         # print(ch)\n",
    "#         for i in range(0,9):\n",
    "#             col_names.append(str(ch)+'-'+str(i))\n",
    "#     col_names.append('patient')\n",
    "#     return col_names\n",
    "\n",
    "def generate_column_names():\n",
    "    channel_order= {'FP1-F7':0, 'F7-T7':1, 'T7-P7':2, 'P7-O1':3, 'FP1-F3':4, 'F3-C3':5, 'C3-P3':6, 'P3-O1':7, 'FP2-F4':8, 'F4-C4':9, 'C4-P4':10, 'P4-O2':11, 'FP2-F8':12, 'F8-T8':13, 'T8-P8-0':14, 'P8-O2':15, 'FZ-CZ':16, 'CZ-PZ':17, 'P7-T7':18, 'T7-FT9':19, 'FT9-FT10':20, 'FT10-T8':21 ,'T8-P8-1':22 }\n",
    "    col_names=[]\n",
    "    for ch in channel_order:\n",
    "        # print(ch)\n",
    "        for i in range(0,9):\n",
    "            col_names.append(str(ch)+'-'+str(i))\n",
    "    # col_names.append('rms')\n",
    "    # col_names.append('sum')\n",
    "    col_names.append('patient')\n",
    "    # print(col_names.shape)\n",
    "    return col_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                  sum       rms  patient\n",
       "0       122056.929688  7.405896      1.0\n",
       "1       119804.921875  7.694022      1.0\n",
       "2        81689.562500  6.464692      1.0\n",
       "3        60762.343750  6.407615      1.0\n",
       "4        48564.589844  6.165314      1.0\n",
       "...               ...       ...      ...\n",
       "110457   13132.047852  0.847515     14.0\n",
       "110458   20350.298828  1.106131     14.0\n",
       "110459   19528.882812  1.343929     14.0\n",
       "110460   16770.392578  1.977222     14.0\n",
       "110461   19704.525391  2.374930     14.0\n",
       "\n",
       "[110462 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sum</th>\n      <th>rms</th>\n      <th>patient</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>122056.929688</td>\n      <td>7.405896</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>119804.921875</td>\n      <td>7.694022</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>81689.562500</td>\n      <td>6.464692</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>60762.343750</td>\n      <td>6.407615</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>48564.589844</td>\n      <td>6.165314</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>110457</th>\n      <td>13132.047852</td>\n      <td>0.847515</td>\n      <td>14.0</td>\n    </tr>\n    <tr>\n      <th>110458</th>\n      <td>20350.298828</td>\n      <td>1.106131</td>\n      <td>14.0</td>\n    </tr>\n    <tr>\n      <th>110459</th>\n      <td>19528.882812</td>\n      <td>1.343929</td>\n      <td>14.0</td>\n    </tr>\n    <tr>\n      <th>110460</th>\n      <td>16770.392578</td>\n      <td>1.977222</td>\n      <td>14.0</td>\n    </tr>\n    <tr>\n      <th>110461</th>\n      <td>19704.525391</td>\n      <td>2.374930</td>\n      <td>14.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>110462 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 485
    }
   ],
   "source": [
    "df_sums =pd.DataFrame(data=X_sum , columns=['sum', 'rms', 'patient'])\n",
    "df_sums"
   ]
  },
  {
   "source": [
    "df=pd.DataFrame(data=X, columns=generate_column_names())\n",
    "# df['patient']=1\n",
    "# df.at[14577:27187,'patient',]=2\n",
    "# df.at[27187:40755, 'patient']=3\n",
    "# df.at[40755:97783, 'patient']=4\n",
    "# df.at[97783:, 'patient']=5\n",
    "\n",
    "# df=df[np.append(df.columns[:50], ['rms', 'sum', 'patient'])]\n",
    "# df['patient']=df_sums['patient']\n",
    "df['sum']=df_sums['sum']\n",
    "df['rms']=df_sums['rms']\n",
    "df['target']=y\n",
    "print(df.shape)\n",
    "df=df.dropna()\n",
    "# df=df.drop([1,4], axis=1)\n",
    "print(df.shape)\n",
    "df.reset_index(drop=True, inplace=True)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 486,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(110462, 211)\n",
      "(110462, 211)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        FP1-F7-0  FP1-F7-1  FP1-F7-2  FP1-F7-3  FP1-F7-4  FP1-F7-5  FP1-F7-6  \\\n",
       "0       0.009253  0.205576  0.015386  0.013003  0.353573  0.068100  0.261663   \n",
       "1       0.010184  0.198871  0.017687  0.014204  0.371332  0.078176  0.244087   \n",
       "2       0.013337  0.209899  0.024952  0.019939  0.382135  0.072422  0.219988   \n",
       "3       0.014367  0.214465  0.024949  0.024575  0.367699  0.068725  0.233418   \n",
       "4       0.024251  0.179508  0.064263  0.053937  0.377249  0.069827  0.200093   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "110457  0.153695  0.185443  0.182544  0.207289  0.194108  0.031253  0.119453   \n",
       "110458  0.127338  0.161348  0.194171  0.223590  0.193580  0.035099  0.135368   \n",
       "110459  0.212475  0.200538  0.215722  0.289813  0.092155  0.019873  0.107063   \n",
       "110460  0.227205  0.221372  0.207406  0.303420  0.066524  0.011218  0.124839   \n",
       "110461  0.216067  0.187700  0.191293  0.314652  0.070303  0.010581  0.132525   \n",
       "\n",
       "        FP1-F7-7      FP1-F7-8   F7-T7-0  ...  T8-P8-1-3  T8-P8-1-4  \\\n",
       "0       0.048393  13087.628906  0.009094  ...   0.013950   0.344800   \n",
       "1       0.050380  13272.797852  0.009179  ...   0.017124   0.360151   \n",
       "2       0.053930   9027.048828  0.010076  ...   0.017145   0.405914   \n",
       "3       0.046182   6688.242676  0.017899  ...   0.014635   0.405534   \n",
       "4       0.030606   4267.430176  0.043423  ...   0.022323   0.309459   \n",
       "...          ...           ...       ...  ...        ...        ...   \n",
       "110457  0.022562    257.937256  0.082895  ...   0.198526   0.238103   \n",
       "110458  0.026710    306.199768  0.056652  ...   0.101892   0.359295   \n",
       "110459  0.019422    297.625916  0.133074  ...   0.143244   0.333949   \n",
       "110460  0.010568    349.006165  0.205929  ...   0.313678   0.157901   \n",
       "110461  0.007079    396.506714  0.191495  ...   0.267924   0.138023   \n",
       "\n",
       "        T8-P8-1-5  T8-P8-1-6  T8-P8-1-7    T8-P8-1-8  patient            sum  \\\n",
       "0        0.081632   0.294163   0.059692  2853.293701      1.0  122056.929688   \n",
       "1        0.080480   0.282719   0.057230  2595.387695      1.0  119804.921875   \n",
       "2        0.107520   0.246479   0.072111  2669.577881      1.0   81689.562500   \n",
       "3        0.109894   0.233375   0.072846  2570.697998      1.0   60762.343750   \n",
       "4        0.085600   0.301347   0.069259  1922.287476      1.0   48564.589844   \n",
       "...           ...        ...        ...          ...      ...            ...   \n",
       "110457   0.030995   0.114659   0.020887   345.400299     14.0   13132.047852   \n",
       "110458   0.048362   0.163300   0.039990   934.927307     14.0   20350.298828   \n",
       "110459   0.042226   0.145928   0.035688   993.386719     14.0   19528.882812   \n",
       "110460   0.014685   0.068349   0.009225   466.282196     14.0   16770.392578   \n",
       "110461   0.013781   0.063205   0.007013   543.707275     14.0   19704.525391   \n",
       "\n",
       "             rms  target  \n",
       "0       7.405896       0  \n",
       "1       7.694022       0  \n",
       "2       6.464692       0  \n",
       "3       6.407615       0  \n",
       "4       6.165314       0  \n",
       "...          ...     ...  \n",
       "110457  0.847515       0  \n",
       "110458  1.106131       0  \n",
       "110459  1.343929       0  \n",
       "110460  1.977222       0  \n",
       "110461  2.374930       0  \n",
       "\n",
       "[110462 rows x 211 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FP1-F7-0</th>\n      <th>FP1-F7-1</th>\n      <th>FP1-F7-2</th>\n      <th>FP1-F7-3</th>\n      <th>FP1-F7-4</th>\n      <th>FP1-F7-5</th>\n      <th>FP1-F7-6</th>\n      <th>FP1-F7-7</th>\n      <th>FP1-F7-8</th>\n      <th>F7-T7-0</th>\n      <th>...</th>\n      <th>T8-P8-1-3</th>\n      <th>T8-P8-1-4</th>\n      <th>T8-P8-1-5</th>\n      <th>T8-P8-1-6</th>\n      <th>T8-P8-1-7</th>\n      <th>T8-P8-1-8</th>\n      <th>patient</th>\n      <th>sum</th>\n      <th>rms</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.009253</td>\n      <td>0.205576</td>\n      <td>0.015386</td>\n      <td>0.013003</td>\n      <td>0.353573</td>\n      <td>0.068100</td>\n      <td>0.261663</td>\n      <td>0.048393</td>\n      <td>13087.628906</td>\n      <td>0.009094</td>\n      <td>...</td>\n      <td>0.013950</td>\n      <td>0.344800</td>\n      <td>0.081632</td>\n      <td>0.294163</td>\n      <td>0.059692</td>\n      <td>2853.293701</td>\n      <td>1.0</td>\n      <td>122056.929688</td>\n      <td>7.405896</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.010184</td>\n      <td>0.198871</td>\n      <td>0.017687</td>\n      <td>0.014204</td>\n      <td>0.371332</td>\n      <td>0.078176</td>\n      <td>0.244087</td>\n      <td>0.050380</td>\n      <td>13272.797852</td>\n      <td>0.009179</td>\n      <td>...</td>\n      <td>0.017124</td>\n      <td>0.360151</td>\n      <td>0.080480</td>\n      <td>0.282719</td>\n      <td>0.057230</td>\n      <td>2595.387695</td>\n      <td>1.0</td>\n      <td>119804.921875</td>\n      <td>7.694022</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.013337</td>\n      <td>0.209899</td>\n      <td>0.024952</td>\n      <td>0.019939</td>\n      <td>0.382135</td>\n      <td>0.072422</td>\n      <td>0.219988</td>\n      <td>0.053930</td>\n      <td>9027.048828</td>\n      <td>0.010076</td>\n      <td>...</td>\n      <td>0.017145</td>\n      <td>0.405914</td>\n      <td>0.107520</td>\n      <td>0.246479</td>\n      <td>0.072111</td>\n      <td>2669.577881</td>\n      <td>1.0</td>\n      <td>81689.562500</td>\n      <td>6.464692</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.014367</td>\n      <td>0.214465</td>\n      <td>0.024949</td>\n      <td>0.024575</td>\n      <td>0.367699</td>\n      <td>0.068725</td>\n      <td>0.233418</td>\n      <td>0.046182</td>\n      <td>6688.242676</td>\n      <td>0.017899</td>\n      <td>...</td>\n      <td>0.014635</td>\n      <td>0.405534</td>\n      <td>0.109894</td>\n      <td>0.233375</td>\n      <td>0.072846</td>\n      <td>2570.697998</td>\n      <td>1.0</td>\n      <td>60762.343750</td>\n      <td>6.407615</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.024251</td>\n      <td>0.179508</td>\n      <td>0.064263</td>\n      <td>0.053937</td>\n      <td>0.377249</td>\n      <td>0.069827</td>\n      <td>0.200093</td>\n      <td>0.030606</td>\n      <td>4267.430176</td>\n      <td>0.043423</td>\n      <td>...</td>\n      <td>0.022323</td>\n      <td>0.309459</td>\n      <td>0.085600</td>\n      <td>0.301347</td>\n      <td>0.069259</td>\n      <td>1922.287476</td>\n      <td>1.0</td>\n      <td>48564.589844</td>\n      <td>6.165314</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>110457</th>\n      <td>0.153695</td>\n      <td>0.185443</td>\n      <td>0.182544</td>\n      <td>0.207289</td>\n      <td>0.194108</td>\n      <td>0.031253</td>\n      <td>0.119453</td>\n      <td>0.022562</td>\n      <td>257.937256</td>\n      <td>0.082895</td>\n      <td>...</td>\n      <td>0.198526</td>\n      <td>0.238103</td>\n      <td>0.030995</td>\n      <td>0.114659</td>\n      <td>0.020887</td>\n      <td>345.400299</td>\n      <td>14.0</td>\n      <td>13132.047852</td>\n      <td>0.847515</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>110458</th>\n      <td>0.127338</td>\n      <td>0.161348</td>\n      <td>0.194171</td>\n      <td>0.223590</td>\n      <td>0.193580</td>\n      <td>0.035099</td>\n      <td>0.135368</td>\n      <td>0.026710</td>\n      <td>306.199768</td>\n      <td>0.056652</td>\n      <td>...</td>\n      <td>0.101892</td>\n      <td>0.359295</td>\n      <td>0.048362</td>\n      <td>0.163300</td>\n      <td>0.039990</td>\n      <td>934.927307</td>\n      <td>14.0</td>\n      <td>20350.298828</td>\n      <td>1.106131</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>110459</th>\n      <td>0.212475</td>\n      <td>0.200538</td>\n      <td>0.215722</td>\n      <td>0.289813</td>\n      <td>0.092155</td>\n      <td>0.019873</td>\n      <td>0.107063</td>\n      <td>0.019422</td>\n      <td>297.625916</td>\n      <td>0.133074</td>\n      <td>...</td>\n      <td>0.143244</td>\n      <td>0.333949</td>\n      <td>0.042226</td>\n      <td>0.145928</td>\n      <td>0.035688</td>\n      <td>993.386719</td>\n      <td>14.0</td>\n      <td>19528.882812</td>\n      <td>1.343929</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>110460</th>\n      <td>0.227205</td>\n      <td>0.221372</td>\n      <td>0.207406</td>\n      <td>0.303420</td>\n      <td>0.066524</td>\n      <td>0.011218</td>\n      <td>0.124839</td>\n      <td>0.010568</td>\n      <td>349.006165</td>\n      <td>0.205929</td>\n      <td>...</td>\n      <td>0.313678</td>\n      <td>0.157901</td>\n      <td>0.014685</td>\n      <td>0.068349</td>\n      <td>0.009225</td>\n      <td>466.282196</td>\n      <td>14.0</td>\n      <td>16770.392578</td>\n      <td>1.977222</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>110461</th>\n      <td>0.216067</td>\n      <td>0.187700</td>\n      <td>0.191293</td>\n      <td>0.314652</td>\n      <td>0.070303</td>\n      <td>0.010581</td>\n      <td>0.132525</td>\n      <td>0.007079</td>\n      <td>396.506714</td>\n      <td>0.191495</td>\n      <td>...</td>\n      <td>0.267924</td>\n      <td>0.138023</td>\n      <td>0.013781</td>\n      <td>0.063205</td>\n      <td>0.007013</td>\n      <td>543.707275</td>\n      <td>14.0</td>\n      <td>19704.525391</td>\n      <td>2.374930</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>110462 rows × 211 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 487
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{1.0: 341725.9808489427, 3.0: 183551.2078667481, 6.0: 825746.9135398668, 7.0: 951636.5401811939, 8.0: 185861.8824585347, 10.0: 222518.6098710113, 14.0: 28535.77624228168}\n"
     ]
    }
   ],
   "source": [
    "mean_sums={}\n",
    "df[\"mean_sum\"]=0\n",
    "for patient in pd.unique(df['patient']):\n",
    "    # patdf=df[df[207]==patient]\n",
    "    # df2[\"mean_sum\"][df2['patient']==patient]=np.mean(df2['sum'][(df2['patient']==patient)&(df2['target']==0)])\n",
    "    mean_sum=np.mean(df['sum'][(df['patient']==patient)&(df['target']==0)])\n",
    "    # df2.where(df2['patient']!=patient, mean_sums[int(patient)])\n",
    "    mean_sums[patient]=(mean_sum)\n",
    "print(mean_sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{1.0: 251.5836950947427, 3.0: 12.775175573289024, 6.0: 225.93468819656715, 7.0: 443.69328131889085, 8.0: 12.10269160905675, 10.0: 58.79644375697765, 14.0: 1.648858093822819}\n"
     ]
    }
   ],
   "source": [
    "mean_rmss={}\n",
    "df[\"mean_rms\"]=0\n",
    "for patient in pd.unique(df['patient']):\n",
    "    # patdf=df[df[207]==patient]\n",
    "    # df2[\"mean_sum\"][df2['patient']==patient]=np.mean(df2['sum'][(df2['patient']==patient)&(df2['target']==0)])\n",
    "    mean_rms=np.mean(df['rms'][(df['patient']==patient)&(df['target']==0)])\n",
    "    # df2.where(df2['patient']!=patient, mean_sums[int(patient)])\n",
    "    mean_rmss[patient]=(mean_rms)\n",
    "print(mean_rmss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        FP1-F7-0  FP1-F7-1  FP1-F7-2  FP1-F7-3  FP1-F7-4  FP1-F7-5  FP1-F7-6  \\\n",
       "0       0.009253  0.205576  0.015386  0.013003  0.353573  0.068100  0.261663   \n",
       "1       0.010184  0.198871  0.017687  0.014204  0.371332  0.078176  0.244087   \n",
       "2       0.013337  0.209899  0.024952  0.019939  0.382135  0.072422  0.219988   \n",
       "3       0.014367  0.214465  0.024949  0.024575  0.367699  0.068725  0.233418   \n",
       "4       0.024251  0.179508  0.064263  0.053937  0.377249  0.069827  0.200093   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "110457  0.153695  0.185443  0.182544  0.207289  0.194108  0.031253  0.119453   \n",
       "110458  0.127338  0.161348  0.194171  0.223590  0.193580  0.035099  0.135368   \n",
       "110459  0.212475  0.200538  0.215722  0.289813  0.092155  0.019873  0.107063   \n",
       "110460  0.227205  0.221372  0.207406  0.303420  0.066524  0.011218  0.124839   \n",
       "110461  0.216067  0.187700  0.191293  0.314652  0.070303  0.010581  0.132525   \n",
       "\n",
       "        FP1-F7-7      FP1-F7-8   F7-T7-0  ...  T8-P8-1-6  T8-P8-1-7  \\\n",
       "0       0.048393  13087.628906  0.009094  ...   0.294163   0.059692   \n",
       "1       0.050380  13272.797852  0.009179  ...   0.282719   0.057230   \n",
       "2       0.053930   9027.048828  0.010076  ...   0.246479   0.072111   \n",
       "3       0.046182   6688.242676  0.017899  ...   0.233375   0.072846   \n",
       "4       0.030606   4267.430176  0.043423  ...   0.301347   0.069259   \n",
       "...          ...           ...       ...  ...        ...        ...   \n",
       "110457  0.022562    257.937256  0.082895  ...   0.114659   0.020887   \n",
       "110458  0.026710    306.199768  0.056652  ...   0.163300   0.039990   \n",
       "110459  0.019422    297.625916  0.133074  ...   0.145928   0.035688   \n",
       "110460  0.010568    349.006165  0.205929  ...   0.068349   0.009225   \n",
       "110461  0.007079    396.506714  0.191495  ...   0.063205   0.007013   \n",
       "\n",
       "          T8-P8-1-8  patient            sum       rms  target       mean_sum  \\\n",
       "0       2853.293701      1.0  122056.929688  7.405896       0  341725.980849   \n",
       "1       2595.387695      1.0  119804.921875  7.694022       0  341725.980849   \n",
       "2       2669.577881      1.0   81689.562500  6.464692       0  341725.980849   \n",
       "3       2570.697998      1.0   60762.343750  6.407615       0  341725.980849   \n",
       "4       1922.287476      1.0   48564.589844  6.165314       0  341725.980849   \n",
       "...             ...      ...            ...       ...     ...            ...   \n",
       "110457   345.400299     14.0   13132.047852  0.847515       0   28535.776242   \n",
       "110458   934.927307     14.0   20350.298828  1.106131       0   28535.776242   \n",
       "110459   993.386719     14.0   19528.882812  1.343929       0   28535.776242   \n",
       "110460   466.282196     14.0   16770.392578  1.977222       0   28535.776242   \n",
       "110461   543.707275     14.0   19704.525391  2.374930       0   28535.776242   \n",
       "\n",
       "        mean_rms  sum_ratio  \n",
       "0              0          0  \n",
       "1              0          0  \n",
       "2              0          0  \n",
       "3              0          0  \n",
       "4              0          0  \n",
       "...          ...        ...  \n",
       "110457         0          0  \n",
       "110458         0          0  \n",
       "110459         0          0  \n",
       "110460         0          0  \n",
       "110461         0          0  \n",
       "\n",
       "[110462 rows x 214 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FP1-F7-0</th>\n      <th>FP1-F7-1</th>\n      <th>FP1-F7-2</th>\n      <th>FP1-F7-3</th>\n      <th>FP1-F7-4</th>\n      <th>FP1-F7-5</th>\n      <th>FP1-F7-6</th>\n      <th>FP1-F7-7</th>\n      <th>FP1-F7-8</th>\n      <th>F7-T7-0</th>\n      <th>...</th>\n      <th>T8-P8-1-6</th>\n      <th>T8-P8-1-7</th>\n      <th>T8-P8-1-8</th>\n      <th>patient</th>\n      <th>sum</th>\n      <th>rms</th>\n      <th>target</th>\n      <th>mean_sum</th>\n      <th>mean_rms</th>\n      <th>sum_ratio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.009253</td>\n      <td>0.205576</td>\n      <td>0.015386</td>\n      <td>0.013003</td>\n      <td>0.353573</td>\n      <td>0.068100</td>\n      <td>0.261663</td>\n      <td>0.048393</td>\n      <td>13087.628906</td>\n      <td>0.009094</td>\n      <td>...</td>\n      <td>0.294163</td>\n      <td>0.059692</td>\n      <td>2853.293701</td>\n      <td>1.0</td>\n      <td>122056.929688</td>\n      <td>7.405896</td>\n      <td>0</td>\n      <td>341725.980849</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.010184</td>\n      <td>0.198871</td>\n      <td>0.017687</td>\n      <td>0.014204</td>\n      <td>0.371332</td>\n      <td>0.078176</td>\n      <td>0.244087</td>\n      <td>0.050380</td>\n      <td>13272.797852</td>\n      <td>0.009179</td>\n      <td>...</td>\n      <td>0.282719</td>\n      <td>0.057230</td>\n      <td>2595.387695</td>\n      <td>1.0</td>\n      <td>119804.921875</td>\n      <td>7.694022</td>\n      <td>0</td>\n      <td>341725.980849</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.013337</td>\n      <td>0.209899</td>\n      <td>0.024952</td>\n      <td>0.019939</td>\n      <td>0.382135</td>\n      <td>0.072422</td>\n      <td>0.219988</td>\n      <td>0.053930</td>\n      <td>9027.048828</td>\n      <td>0.010076</td>\n      <td>...</td>\n      <td>0.246479</td>\n      <td>0.072111</td>\n      <td>2669.577881</td>\n      <td>1.0</td>\n      <td>81689.562500</td>\n      <td>6.464692</td>\n      <td>0</td>\n      <td>341725.980849</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.014367</td>\n      <td>0.214465</td>\n      <td>0.024949</td>\n      <td>0.024575</td>\n      <td>0.367699</td>\n      <td>0.068725</td>\n      <td>0.233418</td>\n      <td>0.046182</td>\n      <td>6688.242676</td>\n      <td>0.017899</td>\n      <td>...</td>\n      <td>0.233375</td>\n      <td>0.072846</td>\n      <td>2570.697998</td>\n      <td>1.0</td>\n      <td>60762.343750</td>\n      <td>6.407615</td>\n      <td>0</td>\n      <td>341725.980849</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.024251</td>\n      <td>0.179508</td>\n      <td>0.064263</td>\n      <td>0.053937</td>\n      <td>0.377249</td>\n      <td>0.069827</td>\n      <td>0.200093</td>\n      <td>0.030606</td>\n      <td>4267.430176</td>\n      <td>0.043423</td>\n      <td>...</td>\n      <td>0.301347</td>\n      <td>0.069259</td>\n      <td>1922.287476</td>\n      <td>1.0</td>\n      <td>48564.589844</td>\n      <td>6.165314</td>\n      <td>0</td>\n      <td>341725.980849</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>110457</th>\n      <td>0.153695</td>\n      <td>0.185443</td>\n      <td>0.182544</td>\n      <td>0.207289</td>\n      <td>0.194108</td>\n      <td>0.031253</td>\n      <td>0.119453</td>\n      <td>0.022562</td>\n      <td>257.937256</td>\n      <td>0.082895</td>\n      <td>...</td>\n      <td>0.114659</td>\n      <td>0.020887</td>\n      <td>345.400299</td>\n      <td>14.0</td>\n      <td>13132.047852</td>\n      <td>0.847515</td>\n      <td>0</td>\n      <td>28535.776242</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>110458</th>\n      <td>0.127338</td>\n      <td>0.161348</td>\n      <td>0.194171</td>\n      <td>0.223590</td>\n      <td>0.193580</td>\n      <td>0.035099</td>\n      <td>0.135368</td>\n      <td>0.026710</td>\n      <td>306.199768</td>\n      <td>0.056652</td>\n      <td>...</td>\n      <td>0.163300</td>\n      <td>0.039990</td>\n      <td>934.927307</td>\n      <td>14.0</td>\n      <td>20350.298828</td>\n      <td>1.106131</td>\n      <td>0</td>\n      <td>28535.776242</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>110459</th>\n      <td>0.212475</td>\n      <td>0.200538</td>\n      <td>0.215722</td>\n      <td>0.289813</td>\n      <td>0.092155</td>\n      <td>0.019873</td>\n      <td>0.107063</td>\n      <td>0.019422</td>\n      <td>297.625916</td>\n      <td>0.133074</td>\n      <td>...</td>\n      <td>0.145928</td>\n      <td>0.035688</td>\n      <td>993.386719</td>\n      <td>14.0</td>\n      <td>19528.882812</td>\n      <td>1.343929</td>\n      <td>0</td>\n      <td>28535.776242</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>110460</th>\n      <td>0.227205</td>\n      <td>0.221372</td>\n      <td>0.207406</td>\n      <td>0.303420</td>\n      <td>0.066524</td>\n      <td>0.011218</td>\n      <td>0.124839</td>\n      <td>0.010568</td>\n      <td>349.006165</td>\n      <td>0.205929</td>\n      <td>...</td>\n      <td>0.068349</td>\n      <td>0.009225</td>\n      <td>466.282196</td>\n      <td>14.0</td>\n      <td>16770.392578</td>\n      <td>1.977222</td>\n      <td>0</td>\n      <td>28535.776242</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>110461</th>\n      <td>0.216067</td>\n      <td>0.187700</td>\n      <td>0.191293</td>\n      <td>0.314652</td>\n      <td>0.070303</td>\n      <td>0.010581</td>\n      <td>0.132525</td>\n      <td>0.007079</td>\n      <td>396.506714</td>\n      <td>0.191495</td>\n      <td>...</td>\n      <td>0.063205</td>\n      <td>0.007013</td>\n      <td>543.707275</td>\n      <td>14.0</td>\n      <td>19704.525391</td>\n      <td>2.374930</td>\n      <td>0</td>\n      <td>28535.776242</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>110462 rows × 214 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 490
    }
   ],
   "source": [
    "df['sum_ratio']=0\n",
    "for patient in pd.unique(df['patient']):\n",
    "    df['mean_sum'].where(df['patient']!=patient, mean_sums[int(patient)], inplace=True)\n",
    "\n",
    "    # df2['new']=df2['sum']/df2[\"mean_sum\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        FP1-F7-0  FP1-F7-1  FP1-F7-2  FP1-F7-3  FP1-F7-4  FP1-F7-5  FP1-F7-6  \\\n",
       "0       0.009253  0.205576  0.015386  0.013003  0.353573  0.068100  0.261663   \n",
       "1       0.010184  0.198871  0.017687  0.014204  0.371332  0.078176  0.244087   \n",
       "2       0.013337  0.209899  0.024952  0.019939  0.382135  0.072422  0.219988   \n",
       "3       0.014367  0.214465  0.024949  0.024575  0.367699  0.068725  0.233418   \n",
       "4       0.024251  0.179508  0.064263  0.053937  0.377249  0.069827  0.200093   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "110457  0.153695  0.185443  0.182544  0.207289  0.194108  0.031253  0.119453   \n",
       "110458  0.127338  0.161348  0.194171  0.223590  0.193580  0.035099  0.135368   \n",
       "110459  0.212475  0.200538  0.215722  0.289813  0.092155  0.019873  0.107063   \n",
       "110460  0.227205  0.221372  0.207406  0.303420  0.066524  0.011218  0.124839   \n",
       "110461  0.216067  0.187700  0.191293  0.314652  0.070303  0.010581  0.132525   \n",
       "\n",
       "        FP1-F7-7      FP1-F7-8   F7-T7-0  ...  T8-P8-1-7    T8-P8-1-8  \\\n",
       "0       0.048393  13087.628906  0.009094  ...   0.059692  2853.293701   \n",
       "1       0.050380  13272.797852  0.009179  ...   0.057230  2595.387695   \n",
       "2       0.053930   9027.048828  0.010076  ...   0.072111  2669.577881   \n",
       "3       0.046182   6688.242676  0.017899  ...   0.072846  2570.697998   \n",
       "4       0.030606   4267.430176  0.043423  ...   0.069259  1922.287476   \n",
       "...          ...           ...       ...  ...        ...          ...   \n",
       "110457  0.022562    257.937256  0.082895  ...   0.020887   345.400299   \n",
       "110458  0.026710    306.199768  0.056652  ...   0.039990   934.927307   \n",
       "110459  0.019422    297.625916  0.133074  ...   0.035688   993.386719   \n",
       "110460  0.010568    349.006165  0.205929  ...   0.009225   466.282196   \n",
       "110461  0.007079    396.506714  0.191495  ...   0.007013   543.707275   \n",
       "\n",
       "        patient            sum       rms  target       mean_sum    mean_rms  \\\n",
       "0           1.0  122056.929688  7.405896       0  341725.980849  251.583695   \n",
       "1           1.0  119804.921875  7.694022       0  341725.980849  251.583695   \n",
       "2           1.0   81689.562500  6.464692       0  341725.980849  251.583695   \n",
       "3           1.0   60762.343750  6.407615       0  341725.980849  251.583695   \n",
       "4           1.0   48564.589844  6.165314       0  341725.980849  251.583695   \n",
       "...         ...            ...       ...     ...            ...         ...   \n",
       "110457     14.0   13132.047852  0.847515       0   28535.776242    1.648858   \n",
       "110458     14.0   20350.298828  1.106131       0   28535.776242    1.648858   \n",
       "110459     14.0   19528.882812  1.343929       0   28535.776242    1.648858   \n",
       "110460     14.0   16770.392578  1.977222       0   28535.776242    1.648858   \n",
       "110461     14.0   19704.525391  2.374930       0   28535.776242    1.648858   \n",
       "\n",
       "        sum_ratio  rms_ratio  \n",
       "0               0          0  \n",
       "1               0          0  \n",
       "2               0          0  \n",
       "3               0          0  \n",
       "4               0          0  \n",
       "...           ...        ...  \n",
       "110457          0          0  \n",
       "110458          0          0  \n",
       "110459          0          0  \n",
       "110460          0          0  \n",
       "110461          0          0  \n",
       "\n",
       "[110462 rows x 215 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FP1-F7-0</th>\n      <th>FP1-F7-1</th>\n      <th>FP1-F7-2</th>\n      <th>FP1-F7-3</th>\n      <th>FP1-F7-4</th>\n      <th>FP1-F7-5</th>\n      <th>FP1-F7-6</th>\n      <th>FP1-F7-7</th>\n      <th>FP1-F7-8</th>\n      <th>F7-T7-0</th>\n      <th>...</th>\n      <th>T8-P8-1-7</th>\n      <th>T8-P8-1-8</th>\n      <th>patient</th>\n      <th>sum</th>\n      <th>rms</th>\n      <th>target</th>\n      <th>mean_sum</th>\n      <th>mean_rms</th>\n      <th>sum_ratio</th>\n      <th>rms_ratio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.009253</td>\n      <td>0.205576</td>\n      <td>0.015386</td>\n      <td>0.013003</td>\n      <td>0.353573</td>\n      <td>0.068100</td>\n      <td>0.261663</td>\n      <td>0.048393</td>\n      <td>13087.628906</td>\n      <td>0.009094</td>\n      <td>...</td>\n      <td>0.059692</td>\n      <td>2853.293701</td>\n      <td>1.0</td>\n      <td>122056.929688</td>\n      <td>7.405896</td>\n      <td>0</td>\n      <td>341725.980849</td>\n      <td>251.583695</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.010184</td>\n      <td>0.198871</td>\n      <td>0.017687</td>\n      <td>0.014204</td>\n      <td>0.371332</td>\n      <td>0.078176</td>\n      <td>0.244087</td>\n      <td>0.050380</td>\n      <td>13272.797852</td>\n      <td>0.009179</td>\n      <td>...</td>\n      <td>0.057230</td>\n      <td>2595.387695</td>\n      <td>1.0</td>\n      <td>119804.921875</td>\n      <td>7.694022</td>\n      <td>0</td>\n      <td>341725.980849</td>\n      <td>251.583695</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.013337</td>\n      <td>0.209899</td>\n      <td>0.024952</td>\n      <td>0.019939</td>\n      <td>0.382135</td>\n      <td>0.072422</td>\n      <td>0.219988</td>\n      <td>0.053930</td>\n      <td>9027.048828</td>\n      <td>0.010076</td>\n      <td>...</td>\n      <td>0.072111</td>\n      <td>2669.577881</td>\n      <td>1.0</td>\n      <td>81689.562500</td>\n      <td>6.464692</td>\n      <td>0</td>\n      <td>341725.980849</td>\n      <td>251.583695</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.014367</td>\n      <td>0.214465</td>\n      <td>0.024949</td>\n      <td>0.024575</td>\n      <td>0.367699</td>\n      <td>0.068725</td>\n      <td>0.233418</td>\n      <td>0.046182</td>\n      <td>6688.242676</td>\n      <td>0.017899</td>\n      <td>...</td>\n      <td>0.072846</td>\n      <td>2570.697998</td>\n      <td>1.0</td>\n      <td>60762.343750</td>\n      <td>6.407615</td>\n      <td>0</td>\n      <td>341725.980849</td>\n      <td>251.583695</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.024251</td>\n      <td>0.179508</td>\n      <td>0.064263</td>\n      <td>0.053937</td>\n      <td>0.377249</td>\n      <td>0.069827</td>\n      <td>0.200093</td>\n      <td>0.030606</td>\n      <td>4267.430176</td>\n      <td>0.043423</td>\n      <td>...</td>\n      <td>0.069259</td>\n      <td>1922.287476</td>\n      <td>1.0</td>\n      <td>48564.589844</td>\n      <td>6.165314</td>\n      <td>0</td>\n      <td>341725.980849</td>\n      <td>251.583695</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>110457</th>\n      <td>0.153695</td>\n      <td>0.185443</td>\n      <td>0.182544</td>\n      <td>0.207289</td>\n      <td>0.194108</td>\n      <td>0.031253</td>\n      <td>0.119453</td>\n      <td>0.022562</td>\n      <td>257.937256</td>\n      <td>0.082895</td>\n      <td>...</td>\n      <td>0.020887</td>\n      <td>345.400299</td>\n      <td>14.0</td>\n      <td>13132.047852</td>\n      <td>0.847515</td>\n      <td>0</td>\n      <td>28535.776242</td>\n      <td>1.648858</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>110458</th>\n      <td>0.127338</td>\n      <td>0.161348</td>\n      <td>0.194171</td>\n      <td>0.223590</td>\n      <td>0.193580</td>\n      <td>0.035099</td>\n      <td>0.135368</td>\n      <td>0.026710</td>\n      <td>306.199768</td>\n      <td>0.056652</td>\n      <td>...</td>\n      <td>0.039990</td>\n      <td>934.927307</td>\n      <td>14.0</td>\n      <td>20350.298828</td>\n      <td>1.106131</td>\n      <td>0</td>\n      <td>28535.776242</td>\n      <td>1.648858</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>110459</th>\n      <td>0.212475</td>\n      <td>0.200538</td>\n      <td>0.215722</td>\n      <td>0.289813</td>\n      <td>0.092155</td>\n      <td>0.019873</td>\n      <td>0.107063</td>\n      <td>0.019422</td>\n      <td>297.625916</td>\n      <td>0.133074</td>\n      <td>...</td>\n      <td>0.035688</td>\n      <td>993.386719</td>\n      <td>14.0</td>\n      <td>19528.882812</td>\n      <td>1.343929</td>\n      <td>0</td>\n      <td>28535.776242</td>\n      <td>1.648858</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>110460</th>\n      <td>0.227205</td>\n      <td>0.221372</td>\n      <td>0.207406</td>\n      <td>0.303420</td>\n      <td>0.066524</td>\n      <td>0.011218</td>\n      <td>0.124839</td>\n      <td>0.010568</td>\n      <td>349.006165</td>\n      <td>0.205929</td>\n      <td>...</td>\n      <td>0.009225</td>\n      <td>466.282196</td>\n      <td>14.0</td>\n      <td>16770.392578</td>\n      <td>1.977222</td>\n      <td>0</td>\n      <td>28535.776242</td>\n      <td>1.648858</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>110461</th>\n      <td>0.216067</td>\n      <td>0.187700</td>\n      <td>0.191293</td>\n      <td>0.314652</td>\n      <td>0.070303</td>\n      <td>0.010581</td>\n      <td>0.132525</td>\n      <td>0.007079</td>\n      <td>396.506714</td>\n      <td>0.191495</td>\n      <td>...</td>\n      <td>0.007013</td>\n      <td>543.707275</td>\n      <td>14.0</td>\n      <td>19704.525391</td>\n      <td>2.374930</td>\n      <td>0</td>\n      <td>28535.776242</td>\n      <td>1.648858</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>110462 rows × 215 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 491
    }
   ],
   "source": [
    "df['rms_ratio']=0\n",
    "for patient in pd.unique(df['patient']):\n",
    "    df['mean_rms'].where(df['patient']!=patient, mean_rmss[int(patient)], inplace=True)\n",
    "\n",
    "    # df2['new']=df2['sum']/df2[\"mean_sum\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rms_ratio']=df['rms']/df['mean_rms']\n",
    "df['sum_ratio']=df['sum']/df['mean_sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        FP1-F7-0  FP1-F7-1  FP1-F7-2  FP1-F7-3  FP1-F7-4  FP1-F7-5  FP1-F7-6  \\\n",
       "0       0.009253  0.205576  0.015386  0.013003  0.353573  0.068100  0.261663   \n",
       "1       0.010184  0.198871  0.017687  0.014204  0.371332  0.078176  0.244087   \n",
       "2       0.013337  0.209899  0.024952  0.019939  0.382135  0.072422  0.219988   \n",
       "3       0.014367  0.214465  0.024949  0.024575  0.367699  0.068725  0.233418   \n",
       "4       0.024251  0.179508  0.064263  0.053937  0.377249  0.069827  0.200093   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "110457  0.153695  0.185443  0.182544  0.207289  0.194108  0.031253  0.119453   \n",
       "110458  0.127338  0.161348  0.194171  0.223590  0.193580  0.035099  0.135368   \n",
       "110459  0.212475  0.200538  0.215722  0.289813  0.092155  0.019873  0.107063   \n",
       "110460  0.227205  0.221372  0.207406  0.303420  0.066524  0.011218  0.124839   \n",
       "110461  0.216067  0.187700  0.191293  0.314652  0.070303  0.010581  0.132525   \n",
       "\n",
       "        FP1-F7-7      FP1-F7-8   F7-T7-0  ...    T8-P8-1-8  patient  \\\n",
       "0       0.048393  13087.628906  0.009094  ...  2853.293701      1.0   \n",
       "1       0.050380  13272.797852  0.009179  ...  2595.387695      1.0   \n",
       "2       0.053930   9027.048828  0.010076  ...  2669.577881      1.0   \n",
       "3       0.046182   6688.242676  0.017899  ...  2570.697998      1.0   \n",
       "4       0.030606   4267.430176  0.043423  ...  1922.287476      1.0   \n",
       "...          ...           ...       ...  ...          ...      ...   \n",
       "110457  0.022562    257.937256  0.082895  ...   345.400299     14.0   \n",
       "110458  0.026710    306.199768  0.056652  ...   934.927307     14.0   \n",
       "110459  0.019422    297.625916  0.133074  ...   993.386719     14.0   \n",
       "110460  0.010568    349.006165  0.205929  ...   466.282196     14.0   \n",
       "110461  0.007079    396.506714  0.191495  ...   543.707275     14.0   \n",
       "\n",
       "                  sum       rms  target       mean_sum    mean_rms  sum_ratio  \\\n",
       "0       122056.929688  7.405896       0  341725.980849  251.583695   0.357178   \n",
       "1       119804.921875  7.694022       0  341725.980849  251.583695   0.350588   \n",
       "2        81689.562500  6.464692       0  341725.980849  251.583695   0.239050   \n",
       "3        60762.343750  6.407615       0  341725.980849  251.583695   0.177810   \n",
       "4        48564.589844  6.165314       0  341725.980849  251.583695   0.142116   \n",
       "...               ...       ...     ...            ...         ...        ...   \n",
       "110457   13132.047852  0.847515       0   28535.776242    1.648858   0.460196   \n",
       "110458   20350.298828  1.106131       0   28535.776242    1.648858   0.713150   \n",
       "110459   19528.882812  1.343929       0   28535.776242    1.648858   0.684365   \n",
       "110460   16770.392578  1.977222       0   28535.776242    1.648858   0.587697   \n",
       "110461   19704.525391  2.374930       0   28535.776242    1.648858   0.690520   \n",
       "\n",
       "        rms_ratio  seizure_number  \n",
       "0        0.029437               0  \n",
       "1        0.030582               0  \n",
       "2        0.025696               0  \n",
       "3        0.025469               0  \n",
       "4        0.024506               0  \n",
       "...           ...             ...  \n",
       "110457   0.514001               0  \n",
       "110458   0.670847               0  \n",
       "110459   0.815066               0  \n",
       "110460   1.199146               0  \n",
       "110461   1.440348               0  \n",
       "\n",
       "[110462 rows x 216 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FP1-F7-0</th>\n      <th>FP1-F7-1</th>\n      <th>FP1-F7-2</th>\n      <th>FP1-F7-3</th>\n      <th>FP1-F7-4</th>\n      <th>FP1-F7-5</th>\n      <th>FP1-F7-6</th>\n      <th>FP1-F7-7</th>\n      <th>FP1-F7-8</th>\n      <th>F7-T7-0</th>\n      <th>...</th>\n      <th>T8-P8-1-8</th>\n      <th>patient</th>\n      <th>sum</th>\n      <th>rms</th>\n      <th>target</th>\n      <th>mean_sum</th>\n      <th>mean_rms</th>\n      <th>sum_ratio</th>\n      <th>rms_ratio</th>\n      <th>seizure_number</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.009253</td>\n      <td>0.205576</td>\n      <td>0.015386</td>\n      <td>0.013003</td>\n      <td>0.353573</td>\n      <td>0.068100</td>\n      <td>0.261663</td>\n      <td>0.048393</td>\n      <td>13087.628906</td>\n      <td>0.009094</td>\n      <td>...</td>\n      <td>2853.293701</td>\n      <td>1.0</td>\n      <td>122056.929688</td>\n      <td>7.405896</td>\n      <td>0</td>\n      <td>341725.980849</td>\n      <td>251.583695</td>\n      <td>0.357178</td>\n      <td>0.029437</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.010184</td>\n      <td>0.198871</td>\n      <td>0.017687</td>\n      <td>0.014204</td>\n      <td>0.371332</td>\n      <td>0.078176</td>\n      <td>0.244087</td>\n      <td>0.050380</td>\n      <td>13272.797852</td>\n      <td>0.009179</td>\n      <td>...</td>\n      <td>2595.387695</td>\n      <td>1.0</td>\n      <td>119804.921875</td>\n      <td>7.694022</td>\n      <td>0</td>\n      <td>341725.980849</td>\n      <td>251.583695</td>\n      <td>0.350588</td>\n      <td>0.030582</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.013337</td>\n      <td>0.209899</td>\n      <td>0.024952</td>\n      <td>0.019939</td>\n      <td>0.382135</td>\n      <td>0.072422</td>\n      <td>0.219988</td>\n      <td>0.053930</td>\n      <td>9027.048828</td>\n      <td>0.010076</td>\n      <td>...</td>\n      <td>2669.577881</td>\n      <td>1.0</td>\n      <td>81689.562500</td>\n      <td>6.464692</td>\n      <td>0</td>\n      <td>341725.980849</td>\n      <td>251.583695</td>\n      <td>0.239050</td>\n      <td>0.025696</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.014367</td>\n      <td>0.214465</td>\n      <td>0.024949</td>\n      <td>0.024575</td>\n      <td>0.367699</td>\n      <td>0.068725</td>\n      <td>0.233418</td>\n      <td>0.046182</td>\n      <td>6688.242676</td>\n      <td>0.017899</td>\n      <td>...</td>\n      <td>2570.697998</td>\n      <td>1.0</td>\n      <td>60762.343750</td>\n      <td>6.407615</td>\n      <td>0</td>\n      <td>341725.980849</td>\n      <td>251.583695</td>\n      <td>0.177810</td>\n      <td>0.025469</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.024251</td>\n      <td>0.179508</td>\n      <td>0.064263</td>\n      <td>0.053937</td>\n      <td>0.377249</td>\n      <td>0.069827</td>\n      <td>0.200093</td>\n      <td>0.030606</td>\n      <td>4267.430176</td>\n      <td>0.043423</td>\n      <td>...</td>\n      <td>1922.287476</td>\n      <td>1.0</td>\n      <td>48564.589844</td>\n      <td>6.165314</td>\n      <td>0</td>\n      <td>341725.980849</td>\n      <td>251.583695</td>\n      <td>0.142116</td>\n      <td>0.024506</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>110457</th>\n      <td>0.153695</td>\n      <td>0.185443</td>\n      <td>0.182544</td>\n      <td>0.207289</td>\n      <td>0.194108</td>\n      <td>0.031253</td>\n      <td>0.119453</td>\n      <td>0.022562</td>\n      <td>257.937256</td>\n      <td>0.082895</td>\n      <td>...</td>\n      <td>345.400299</td>\n      <td>14.0</td>\n      <td>13132.047852</td>\n      <td>0.847515</td>\n      <td>0</td>\n      <td>28535.776242</td>\n      <td>1.648858</td>\n      <td>0.460196</td>\n      <td>0.514001</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>110458</th>\n      <td>0.127338</td>\n      <td>0.161348</td>\n      <td>0.194171</td>\n      <td>0.223590</td>\n      <td>0.193580</td>\n      <td>0.035099</td>\n      <td>0.135368</td>\n      <td>0.026710</td>\n      <td>306.199768</td>\n      <td>0.056652</td>\n      <td>...</td>\n      <td>934.927307</td>\n      <td>14.0</td>\n      <td>20350.298828</td>\n      <td>1.106131</td>\n      <td>0</td>\n      <td>28535.776242</td>\n      <td>1.648858</td>\n      <td>0.713150</td>\n      <td>0.670847</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>110459</th>\n      <td>0.212475</td>\n      <td>0.200538</td>\n      <td>0.215722</td>\n      <td>0.289813</td>\n      <td>0.092155</td>\n      <td>0.019873</td>\n      <td>0.107063</td>\n      <td>0.019422</td>\n      <td>297.625916</td>\n      <td>0.133074</td>\n      <td>...</td>\n      <td>993.386719</td>\n      <td>14.0</td>\n      <td>19528.882812</td>\n      <td>1.343929</td>\n      <td>0</td>\n      <td>28535.776242</td>\n      <td>1.648858</td>\n      <td>0.684365</td>\n      <td>0.815066</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>110460</th>\n      <td>0.227205</td>\n      <td>0.221372</td>\n      <td>0.207406</td>\n      <td>0.303420</td>\n      <td>0.066524</td>\n      <td>0.011218</td>\n      <td>0.124839</td>\n      <td>0.010568</td>\n      <td>349.006165</td>\n      <td>0.205929</td>\n      <td>...</td>\n      <td>466.282196</td>\n      <td>14.0</td>\n      <td>16770.392578</td>\n      <td>1.977222</td>\n      <td>0</td>\n      <td>28535.776242</td>\n      <td>1.648858</td>\n      <td>0.587697</td>\n      <td>1.199146</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>110461</th>\n      <td>0.216067</td>\n      <td>0.187700</td>\n      <td>0.191293</td>\n      <td>0.314652</td>\n      <td>0.070303</td>\n      <td>0.010581</td>\n      <td>0.132525</td>\n      <td>0.007079</td>\n      <td>396.506714</td>\n      <td>0.191495</td>\n      <td>...</td>\n      <td>543.707275</td>\n      <td>14.0</td>\n      <td>19704.525391</td>\n      <td>2.374930</td>\n      <td>0</td>\n      <td>28535.776242</td>\n      <td>1.648858</td>\n      <td>0.690520</td>\n      <td>1.440348</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>110462 rows × 216 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 493
    }
   ],
   "source": [
    "df['seizure_number']=0\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "seizure_number=1\n",
    "for i in range(1, len(df)):\n",
    "    # if df.iloc[i]['target']==2 and df.iloc[i-1]['target']==2:\n",
    "    #     df.iloc[i]['seizure_number']=df.iloc[i-1]['seizure_number']\n",
    "    if df.iloc[i]['target']==2:\n",
    "        df.at[i,'seizure_number']=seizure_number\n",
    "    if (df.iloc[i]['target']!=2 and df.iloc[i-1]['target']==2 ):\n",
    "        seizure_number+=1\n",
    "# df.to_csv(r'df.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        FP1-F7-0  FP1-F7-1  FP1-F7-2  FP1-F7-3  FP1-F7-4  FP1-F7-5  FP1-F7-6  \\\n",
       "9049    0.487906  0.294157  0.062645  0.243455  0.061901  0.003636  0.013767   \n",
       "9050    0.492928  0.287013  0.072026  0.238879  0.060910  0.002932  0.012587   \n",
       "9051    0.406936  0.237590  0.078928  0.220020  0.104659  0.004607  0.020451   \n",
       "9052    0.377607  0.232304  0.089268  0.232302  0.118813  0.004778  0.024522   \n",
       "9053    0.464701  0.204894  0.068319  0.203080  0.098251  0.004644  0.023169   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "108236  0.350583  0.335095  0.148207  0.243422  0.072715  0.004027  0.018495   \n",
       "108237  0.257892  0.372992  0.143660  0.229055  0.104612  0.005055  0.022896   \n",
       "108238  0.228357  0.377390  0.137621  0.221662  0.114477  0.006110  0.024464   \n",
       "108239  0.227919  0.336646  0.152785  0.235380  0.128835  0.008861  0.032484   \n",
       "108240  0.215618  0.250228  0.161290  0.257148  0.178950  0.013886  0.049401   \n",
       "\n",
       "        FP1-F7-7    FP1-F7-8   F7-T7-0  ...    T8-P8-1-8  patient  \\\n",
       "9049    0.003427  733.779602  0.385181  ...  1923.753174      1.0   \n",
       "9050    0.004014  711.672302  0.415166  ...  2015.595825      1.0   \n",
       "9051    0.006975  398.291138  0.365368  ...  1690.714233      1.0   \n",
       "9052    0.006443  364.721436  0.288228  ...  1452.021973      1.0   \n",
       "9053    0.005235  448.785583  0.327284  ...  1480.842529      1.0   \n",
       "...          ...         ...       ...  ...          ...      ...   \n",
       "108236  0.004422  443.893036  0.310951  ...   356.422028     14.0   \n",
       "108237  0.004901  440.472992  0.233394  ...   465.785309     14.0   \n",
       "108238  0.004368  510.064880  0.216920  ...   505.763641     14.0   \n",
       "108239  0.006166  480.779297  0.168591  ...   505.745270     14.0   \n",
       "108240  0.008039  420.604675  0.160744  ...   480.679596     14.0   \n",
       "\n",
       "                 sum       rms  target       mean_sum    mean_rms  sum_ratio  \\\n",
       "9049    28861.935547  6.292221       2  341725.980849  251.583695   0.084459   \n",
       "9050    27132.595703  7.463470       2  341725.980849  251.583695   0.079399   \n",
       "9051    20481.373047  6.541937       2  341725.980849  251.583695   0.059935   \n",
       "9052    18504.693359  6.787939       2  341725.980849  251.583695   0.054151   \n",
       "9053    19626.798828  6.252022       2  341725.980849  251.583695   0.057434   \n",
       "...              ...       ...     ...            ...         ...        ...   \n",
       "108236  11823.984375  0.752936       2   28535.776242    1.648858   0.414357   \n",
       "108237  13798.040039  0.892335       2   28535.776242    1.648858   0.483535   \n",
       "108238  18065.376953  1.142276       2   28535.776242    1.648858   0.633078   \n",
       "108239  17551.761719  1.102245       2   28535.776242    1.648858   0.615079   \n",
       "108240  15780.050781  0.995648       2   28535.776242    1.648858   0.552992   \n",
       "\n",
       "        rms_ratio  seizure_number  \n",
       "9049     0.025010               7  \n",
       "9050     0.029666               7  \n",
       "9051     0.026003               7  \n",
       "9052     0.026981               7  \n",
       "9053     0.024851               7  \n",
       "...           ...             ...  \n",
       "108236   0.456641              47  \n",
       "108237   0.541184              47  \n",
       "108238   0.692768              47  \n",
       "108239   0.668490              47  \n",
       "108240   0.603841              47  \n",
       "\n",
       "[406 rows x 216 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FP1-F7-0</th>\n      <th>FP1-F7-1</th>\n      <th>FP1-F7-2</th>\n      <th>FP1-F7-3</th>\n      <th>FP1-F7-4</th>\n      <th>FP1-F7-5</th>\n      <th>FP1-F7-6</th>\n      <th>FP1-F7-7</th>\n      <th>FP1-F7-8</th>\n      <th>F7-T7-0</th>\n      <th>...</th>\n      <th>T8-P8-1-8</th>\n      <th>patient</th>\n      <th>sum</th>\n      <th>rms</th>\n      <th>target</th>\n      <th>mean_sum</th>\n      <th>mean_rms</th>\n      <th>sum_ratio</th>\n      <th>rms_ratio</th>\n      <th>seizure_number</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9049</th>\n      <td>0.487906</td>\n      <td>0.294157</td>\n      <td>0.062645</td>\n      <td>0.243455</td>\n      <td>0.061901</td>\n      <td>0.003636</td>\n      <td>0.013767</td>\n      <td>0.003427</td>\n      <td>733.779602</td>\n      <td>0.385181</td>\n      <td>...</td>\n      <td>1923.753174</td>\n      <td>1.0</td>\n      <td>28861.935547</td>\n      <td>6.292221</td>\n      <td>2</td>\n      <td>341725.980849</td>\n      <td>251.583695</td>\n      <td>0.084459</td>\n      <td>0.025010</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>9050</th>\n      <td>0.492928</td>\n      <td>0.287013</td>\n      <td>0.072026</td>\n      <td>0.238879</td>\n      <td>0.060910</td>\n      <td>0.002932</td>\n      <td>0.012587</td>\n      <td>0.004014</td>\n      <td>711.672302</td>\n      <td>0.415166</td>\n      <td>...</td>\n      <td>2015.595825</td>\n      <td>1.0</td>\n      <td>27132.595703</td>\n      <td>7.463470</td>\n      <td>2</td>\n      <td>341725.980849</td>\n      <td>251.583695</td>\n      <td>0.079399</td>\n      <td>0.029666</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>9051</th>\n      <td>0.406936</td>\n      <td>0.237590</td>\n      <td>0.078928</td>\n      <td>0.220020</td>\n      <td>0.104659</td>\n      <td>0.004607</td>\n      <td>0.020451</td>\n      <td>0.006975</td>\n      <td>398.291138</td>\n      <td>0.365368</td>\n      <td>...</td>\n      <td>1690.714233</td>\n      <td>1.0</td>\n      <td>20481.373047</td>\n      <td>6.541937</td>\n      <td>2</td>\n      <td>341725.980849</td>\n      <td>251.583695</td>\n      <td>0.059935</td>\n      <td>0.026003</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>9052</th>\n      <td>0.377607</td>\n      <td>0.232304</td>\n      <td>0.089268</td>\n      <td>0.232302</td>\n      <td>0.118813</td>\n      <td>0.004778</td>\n      <td>0.024522</td>\n      <td>0.006443</td>\n      <td>364.721436</td>\n      <td>0.288228</td>\n      <td>...</td>\n      <td>1452.021973</td>\n      <td>1.0</td>\n      <td>18504.693359</td>\n      <td>6.787939</td>\n      <td>2</td>\n      <td>341725.980849</td>\n      <td>251.583695</td>\n      <td>0.054151</td>\n      <td>0.026981</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>9053</th>\n      <td>0.464701</td>\n      <td>0.204894</td>\n      <td>0.068319</td>\n      <td>0.203080</td>\n      <td>0.098251</td>\n      <td>0.004644</td>\n      <td>0.023169</td>\n      <td>0.005235</td>\n      <td>448.785583</td>\n      <td>0.327284</td>\n      <td>...</td>\n      <td>1480.842529</td>\n      <td>1.0</td>\n      <td>19626.798828</td>\n      <td>6.252022</td>\n      <td>2</td>\n      <td>341725.980849</td>\n      <td>251.583695</td>\n      <td>0.057434</td>\n      <td>0.024851</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>108236</th>\n      <td>0.350583</td>\n      <td>0.335095</td>\n      <td>0.148207</td>\n      <td>0.243422</td>\n      <td>0.072715</td>\n      <td>0.004027</td>\n      <td>0.018495</td>\n      <td>0.004422</td>\n      <td>443.893036</td>\n      <td>0.310951</td>\n      <td>...</td>\n      <td>356.422028</td>\n      <td>14.0</td>\n      <td>11823.984375</td>\n      <td>0.752936</td>\n      <td>2</td>\n      <td>28535.776242</td>\n      <td>1.648858</td>\n      <td>0.414357</td>\n      <td>0.456641</td>\n      <td>47</td>\n    </tr>\n    <tr>\n      <th>108237</th>\n      <td>0.257892</td>\n      <td>0.372992</td>\n      <td>0.143660</td>\n      <td>0.229055</td>\n      <td>0.104612</td>\n      <td>0.005055</td>\n      <td>0.022896</td>\n      <td>0.004901</td>\n      <td>440.472992</td>\n      <td>0.233394</td>\n      <td>...</td>\n      <td>465.785309</td>\n      <td>14.0</td>\n      <td>13798.040039</td>\n      <td>0.892335</td>\n      <td>2</td>\n      <td>28535.776242</td>\n      <td>1.648858</td>\n      <td>0.483535</td>\n      <td>0.541184</td>\n      <td>47</td>\n    </tr>\n    <tr>\n      <th>108238</th>\n      <td>0.228357</td>\n      <td>0.377390</td>\n      <td>0.137621</td>\n      <td>0.221662</td>\n      <td>0.114477</td>\n      <td>0.006110</td>\n      <td>0.024464</td>\n      <td>0.004368</td>\n      <td>510.064880</td>\n      <td>0.216920</td>\n      <td>...</td>\n      <td>505.763641</td>\n      <td>14.0</td>\n      <td>18065.376953</td>\n      <td>1.142276</td>\n      <td>2</td>\n      <td>28535.776242</td>\n      <td>1.648858</td>\n      <td>0.633078</td>\n      <td>0.692768</td>\n      <td>47</td>\n    </tr>\n    <tr>\n      <th>108239</th>\n      <td>0.227919</td>\n      <td>0.336646</td>\n      <td>0.152785</td>\n      <td>0.235380</td>\n      <td>0.128835</td>\n      <td>0.008861</td>\n      <td>0.032484</td>\n      <td>0.006166</td>\n      <td>480.779297</td>\n      <td>0.168591</td>\n      <td>...</td>\n      <td>505.745270</td>\n      <td>14.0</td>\n      <td>17551.761719</td>\n      <td>1.102245</td>\n      <td>2</td>\n      <td>28535.776242</td>\n      <td>1.648858</td>\n      <td>0.615079</td>\n      <td>0.668490</td>\n      <td>47</td>\n    </tr>\n    <tr>\n      <th>108240</th>\n      <td>0.215618</td>\n      <td>0.250228</td>\n      <td>0.161290</td>\n      <td>0.257148</td>\n      <td>0.178950</td>\n      <td>0.013886</td>\n      <td>0.049401</td>\n      <td>0.008039</td>\n      <td>420.604675</td>\n      <td>0.160744</td>\n      <td>...</td>\n      <td>480.679596</td>\n      <td>14.0</td>\n      <td>15780.050781</td>\n      <td>0.995648</td>\n      <td>2</td>\n      <td>28535.776242</td>\n      <td>1.648858</td>\n      <td>0.552992</td>\n      <td>0.603841</td>\n      <td>47</td>\n    </tr>\n  </tbody>\n</table>\n<p>406 rows × 216 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 495
    }
   ],
   "source": [
    "test_df=pd.DataFrame()\n",
    "for patient in pd.unique(df['patient']):\n",
    "    # patdf=df[df[207]==patient]\n",
    "    last_seizure=max(df[df['patient']==patient]['seizure_number'])\n",
    "    test_df = test_df.append(df[(df['patient']==patient) & (df['seizure_number']==last_seizure)], ignore_index=False)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([2], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 496
    }
   ],
   "source": [
    "test_df['target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.index.isin(test_df.index) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop('seizure_number', axis='columns', inplace=True)\n",
    "# test_df.drop('seizure_number', axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(110056, 216)"
      ]
     },
     "metadata": {},
     "execution_count": 499
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['FP1-F7-0', 'FP1-F7-1', 'FP1-F7-2', 'FP1-F7-3', 'FP1-F7-4', 'FP1-F7-5',\n",
       "       'FP1-F7-6', 'FP1-F7-7', 'FP1-F7-8', 'F7-T7-0',\n",
       "       ...\n",
       "       'T8-P8-1-6', 'T8-P8-1-7', 'T8-P8-1-8', 'patient', 'sum', 'rms',\n",
       "       'mean_sum', 'mean_rms', 'sum_ratio', 'rms_ratio'],\n",
       "      dtype='object', length=214)"
      ]
     },
     "metadata": {},
     "execution_count": 500
    }
   ],
   "source": [
    "df.drop(['target', 'seizure_number'], axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        FP1-F7-0  FP1-F7-1  FP1-F7-2  FP1-F7-3  FP1-F7-4  FP1-F7-5  FP1-F7-6  \\\n",
       "0       0.009253  0.205576  0.015386  0.013003  0.353573  0.068100  0.261663   \n",
       "1       0.010184  0.198871  0.017687  0.014204  0.371332  0.078176  0.244087   \n",
       "2       0.013337  0.209899  0.024952  0.019939  0.382135  0.072422  0.219988   \n",
       "3       0.014367  0.214465  0.024949  0.024575  0.367699  0.068725  0.233418   \n",
       "4       0.024251  0.179508  0.064263  0.053937  0.377249  0.069827  0.200093   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "110457  0.153695  0.185443  0.182544  0.207289  0.194108  0.031253  0.119453   \n",
       "110458  0.127338  0.161348  0.194171  0.223590  0.193580  0.035099  0.135368   \n",
       "110459  0.212475  0.200538  0.215722  0.289813  0.092155  0.019873  0.107063   \n",
       "110460  0.227205  0.221372  0.207406  0.303420  0.066524  0.011218  0.124839   \n",
       "110461  0.216067  0.187700  0.191293  0.314652  0.070303  0.010581  0.132525   \n",
       "\n",
       "        FP1-F7-7      FP1-F7-8   F7-T7-0  ...    T8-P8-1-8  patient  \\\n",
       "0       0.048393  13087.628906  0.009094  ...  2853.293701      1.0   \n",
       "1       0.050380  13272.797852  0.009179  ...  2595.387695      1.0   \n",
       "2       0.053930   9027.048828  0.010076  ...  2669.577881      1.0   \n",
       "3       0.046182   6688.242676  0.017899  ...  2570.697998      1.0   \n",
       "4       0.030606   4267.430176  0.043423  ...  1922.287476      1.0   \n",
       "...          ...           ...       ...  ...          ...      ...   \n",
       "110457  0.022562    257.937256  0.082895  ...   345.400299     14.0   \n",
       "110458  0.026710    306.199768  0.056652  ...   934.927307     14.0   \n",
       "110459  0.019422    297.625916  0.133074  ...   993.386719     14.0   \n",
       "110460  0.010568    349.006165  0.205929  ...   466.282196     14.0   \n",
       "110461  0.007079    396.506714  0.191495  ...   543.707275     14.0   \n",
       "\n",
       "                  sum       rms  target       mean_sum    mean_rms  sum_ratio  \\\n",
       "0       122056.929688  7.405896       0  341725.980849  251.583695   0.357178   \n",
       "1       119804.921875  7.694022       0  341725.980849  251.583695   0.350588   \n",
       "2        81689.562500  6.464692       0  341725.980849  251.583695   0.239050   \n",
       "3        60762.343750  6.407615       0  341725.980849  251.583695   0.177810   \n",
       "4        48564.589844  6.165314       0  341725.980849  251.583695   0.142116   \n",
       "...               ...       ...     ...            ...         ...        ...   \n",
       "110457   13132.047852  0.847515       0   28535.776242    1.648858   0.460196   \n",
       "110458   20350.298828  1.106131       0   28535.776242    1.648858   0.713150   \n",
       "110459   19528.882812  1.343929       0   28535.776242    1.648858   0.684365   \n",
       "110460   16770.392578  1.977222       0   28535.776242    1.648858   0.587697   \n",
       "110461   19704.525391  2.374930       0   28535.776242    1.648858   0.690520   \n",
       "\n",
       "        rms_ratio  seizure_number  \n",
       "0        0.029437               0  \n",
       "1        0.030582               0  \n",
       "2        0.025696               0  \n",
       "3        0.025469               0  \n",
       "4        0.024506               0  \n",
       "...           ...             ...  \n",
       "110457   0.514001               0  \n",
       "110458   0.670847               0  \n",
       "110459   0.815066               0  \n",
       "110460   1.199146               0  \n",
       "110461   1.440348               0  \n",
       "\n",
       "[110056 rows x 216 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FP1-F7-0</th>\n      <th>FP1-F7-1</th>\n      <th>FP1-F7-2</th>\n      <th>FP1-F7-3</th>\n      <th>FP1-F7-4</th>\n      <th>FP1-F7-5</th>\n      <th>FP1-F7-6</th>\n      <th>FP1-F7-7</th>\n      <th>FP1-F7-8</th>\n      <th>F7-T7-0</th>\n      <th>...</th>\n      <th>T8-P8-1-8</th>\n      <th>patient</th>\n      <th>sum</th>\n      <th>rms</th>\n      <th>target</th>\n      <th>mean_sum</th>\n      <th>mean_rms</th>\n      <th>sum_ratio</th>\n      <th>rms_ratio</th>\n      <th>seizure_number</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.009253</td>\n      <td>0.205576</td>\n      <td>0.015386</td>\n      <td>0.013003</td>\n      <td>0.353573</td>\n      <td>0.068100</td>\n      <td>0.261663</td>\n      <td>0.048393</td>\n      <td>13087.628906</td>\n      <td>0.009094</td>\n      <td>...</td>\n      <td>2853.293701</td>\n      <td>1.0</td>\n      <td>122056.929688</td>\n      <td>7.405896</td>\n      <td>0</td>\n      <td>341725.980849</td>\n      <td>251.583695</td>\n      <td>0.357178</td>\n      <td>0.029437</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.010184</td>\n      <td>0.198871</td>\n      <td>0.017687</td>\n      <td>0.014204</td>\n      <td>0.371332</td>\n      <td>0.078176</td>\n      <td>0.244087</td>\n      <td>0.050380</td>\n      <td>13272.797852</td>\n      <td>0.009179</td>\n      <td>...</td>\n      <td>2595.387695</td>\n      <td>1.0</td>\n      <td>119804.921875</td>\n      <td>7.694022</td>\n      <td>0</td>\n      <td>341725.980849</td>\n      <td>251.583695</td>\n      <td>0.350588</td>\n      <td>0.030582</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.013337</td>\n      <td>0.209899</td>\n      <td>0.024952</td>\n      <td>0.019939</td>\n      <td>0.382135</td>\n      <td>0.072422</td>\n      <td>0.219988</td>\n      <td>0.053930</td>\n      <td>9027.048828</td>\n      <td>0.010076</td>\n      <td>...</td>\n      <td>2669.577881</td>\n      <td>1.0</td>\n      <td>81689.562500</td>\n      <td>6.464692</td>\n      <td>0</td>\n      <td>341725.980849</td>\n      <td>251.583695</td>\n      <td>0.239050</td>\n      <td>0.025696</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.014367</td>\n      <td>0.214465</td>\n      <td>0.024949</td>\n      <td>0.024575</td>\n      <td>0.367699</td>\n      <td>0.068725</td>\n      <td>0.233418</td>\n      <td>0.046182</td>\n      <td>6688.242676</td>\n      <td>0.017899</td>\n      <td>...</td>\n      <td>2570.697998</td>\n      <td>1.0</td>\n      <td>60762.343750</td>\n      <td>6.407615</td>\n      <td>0</td>\n      <td>341725.980849</td>\n      <td>251.583695</td>\n      <td>0.177810</td>\n      <td>0.025469</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.024251</td>\n      <td>0.179508</td>\n      <td>0.064263</td>\n      <td>0.053937</td>\n      <td>0.377249</td>\n      <td>0.069827</td>\n      <td>0.200093</td>\n      <td>0.030606</td>\n      <td>4267.430176</td>\n      <td>0.043423</td>\n      <td>...</td>\n      <td>1922.287476</td>\n      <td>1.0</td>\n      <td>48564.589844</td>\n      <td>6.165314</td>\n      <td>0</td>\n      <td>341725.980849</td>\n      <td>251.583695</td>\n      <td>0.142116</td>\n      <td>0.024506</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>110457</th>\n      <td>0.153695</td>\n      <td>0.185443</td>\n      <td>0.182544</td>\n      <td>0.207289</td>\n      <td>0.194108</td>\n      <td>0.031253</td>\n      <td>0.119453</td>\n      <td>0.022562</td>\n      <td>257.937256</td>\n      <td>0.082895</td>\n      <td>...</td>\n      <td>345.400299</td>\n      <td>14.0</td>\n      <td>13132.047852</td>\n      <td>0.847515</td>\n      <td>0</td>\n      <td>28535.776242</td>\n      <td>1.648858</td>\n      <td>0.460196</td>\n      <td>0.514001</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>110458</th>\n      <td>0.127338</td>\n      <td>0.161348</td>\n      <td>0.194171</td>\n      <td>0.223590</td>\n      <td>0.193580</td>\n      <td>0.035099</td>\n      <td>0.135368</td>\n      <td>0.026710</td>\n      <td>306.199768</td>\n      <td>0.056652</td>\n      <td>...</td>\n      <td>934.927307</td>\n      <td>14.0</td>\n      <td>20350.298828</td>\n      <td>1.106131</td>\n      <td>0</td>\n      <td>28535.776242</td>\n      <td>1.648858</td>\n      <td>0.713150</td>\n      <td>0.670847</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>110459</th>\n      <td>0.212475</td>\n      <td>0.200538</td>\n      <td>0.215722</td>\n      <td>0.289813</td>\n      <td>0.092155</td>\n      <td>0.019873</td>\n      <td>0.107063</td>\n      <td>0.019422</td>\n      <td>297.625916</td>\n      <td>0.133074</td>\n      <td>...</td>\n      <td>993.386719</td>\n      <td>14.0</td>\n      <td>19528.882812</td>\n      <td>1.343929</td>\n      <td>0</td>\n      <td>28535.776242</td>\n      <td>1.648858</td>\n      <td>0.684365</td>\n      <td>0.815066</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>110460</th>\n      <td>0.227205</td>\n      <td>0.221372</td>\n      <td>0.207406</td>\n      <td>0.303420</td>\n      <td>0.066524</td>\n      <td>0.011218</td>\n      <td>0.124839</td>\n      <td>0.010568</td>\n      <td>349.006165</td>\n      <td>0.205929</td>\n      <td>...</td>\n      <td>466.282196</td>\n      <td>14.0</td>\n      <td>16770.392578</td>\n      <td>1.977222</td>\n      <td>0</td>\n      <td>28535.776242</td>\n      <td>1.648858</td>\n      <td>0.587697</td>\n      <td>1.199146</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>110461</th>\n      <td>0.216067</td>\n      <td>0.187700</td>\n      <td>0.191293</td>\n      <td>0.314652</td>\n      <td>0.070303</td>\n      <td>0.010581</td>\n      <td>0.132525</td>\n      <td>0.007079</td>\n      <td>396.506714</td>\n      <td>0.191495</td>\n      <td>...</td>\n      <td>543.707275</td>\n      <td>14.0</td>\n      <td>19704.525391</td>\n      <td>2.374930</td>\n      <td>0</td>\n      <td>28535.776242</td>\n      <td>1.648858</td>\n      <td>0.690520</td>\n      <td>1.440348</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>110056 rows × 216 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 501
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "source": [
    "### train test split"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(2725, 216) (2222, 216)\n"
     ]
    }
   ],
   "source": [
    "df_interictal=df[df['target']==0]\n",
    "df_interictal=df_interictal.sample(frac=0.03)\n",
    "df_preictal=df[df['target']==2]\n",
    "interictal_shape, preictal_shape = df_interictal.shape, df_preictal.shape\n",
    "interictal_shape= df_interictal.shape\n",
    "\n",
    "print(df_interictal.shape,  df_preictal.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_interictal=np.array(df_interictal[df.columns[:-2]]).astype('float32')\n",
    "# y_interictal=np.array(df_interictal['target']).astype('float32')\n",
    "# X_preictal_train  =np.array(df_preictal[df.columns[:-2]]).astype('float32')\n",
    "# y_preictal_train  =np.array(df_preictal['target']).astype('float32')\n",
    "X_interictal=np.array(df_interictal[df.drop(['target', 'seizure_number'], axis=1).columns]).astype('float32')\n",
    "y_interictal=np.array(df_interictal['target']).astype('float32')\n",
    "X_preictal_train  =np.array(df_preictal[df.drop(['target', 'seizure_number'], axis=1).columns]).astype('float32')\n",
    "y_preictal_train  =np.array(df_preictal['target']).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(2725, 214)\n(2725,)\n(2222, 214)\n(2222,)\n"
     ]
    }
   ],
   "source": [
    "print(X_interictal.shape)\n",
    "print(y_interictal.shape)\n",
    "print(X_preictal_train.shape)\n",
    "print(y_preictal_train.shape)"
   ]
  },
  {
   "source": [
    "### train test split"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_interictal_train, X_interictal_test, y_interictal_train, y_interictal_test =train_test_split(X_interictal,y_interictal,test_size=0.1, random_state=42)\n",
    "# X_preictal_train, X_preictal_test, y_preictal_train, y_preictal_test=train_test_split(X_preictal, y_preictal,test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        FP1-F7-0  FP1-F7-1  FP1-F7-2  FP1-F7-3  FP1-F7-4  FP1-F7-5  FP1-F7-6  \\\n",
       "9049    0.487906  0.294157  0.062645  0.243455  0.061901  0.003636  0.013767   \n",
       "9050    0.492928  0.287013  0.072026  0.238879  0.060910  0.002932  0.012587   \n",
       "9051    0.406936  0.237590  0.078928  0.220020  0.104659  0.004607  0.020451   \n",
       "9052    0.377607  0.232304  0.089268  0.232302  0.118813  0.004778  0.024522   \n",
       "9053    0.464701  0.204894  0.068319  0.203080  0.098251  0.004644  0.023169   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "108236  0.350583  0.335095  0.148207  0.243422  0.072715  0.004027  0.018495   \n",
       "108237  0.257892  0.372992  0.143660  0.229055  0.104612  0.005055  0.022896   \n",
       "108238  0.228357  0.377390  0.137621  0.221662  0.114477  0.006110  0.024464   \n",
       "108239  0.227919  0.336646  0.152785  0.235380  0.128835  0.008861  0.032484   \n",
       "108240  0.215618  0.250228  0.161290  0.257148  0.178950  0.013886  0.049401   \n",
       "\n",
       "        FP1-F7-7    FP1-F7-8   F7-T7-0  ...    T8-P8-1-8  patient  \\\n",
       "9049    0.003427  733.779602  0.385181  ...  1923.753174      1.0   \n",
       "9050    0.004014  711.672302  0.415166  ...  2015.595825      1.0   \n",
       "9051    0.006975  398.291138  0.365368  ...  1690.714233      1.0   \n",
       "9052    0.006443  364.721436  0.288228  ...  1452.021973      1.0   \n",
       "9053    0.005235  448.785583  0.327284  ...  1480.842529      1.0   \n",
       "...          ...         ...       ...  ...          ...      ...   \n",
       "108236  0.004422  443.893036  0.310951  ...   356.422028     14.0   \n",
       "108237  0.004901  440.472992  0.233394  ...   465.785309     14.0   \n",
       "108238  0.004368  510.064880  0.216920  ...   505.763641     14.0   \n",
       "108239  0.006166  480.779297  0.168591  ...   505.745270     14.0   \n",
       "108240  0.008039  420.604675  0.160744  ...   480.679596     14.0   \n",
       "\n",
       "                 sum       rms  target       mean_sum    mean_rms  sum_ratio  \\\n",
       "9049    28861.935547  6.292221       2  341725.980849  251.583695   0.084459   \n",
       "9050    27132.595703  7.463470       2  341725.980849  251.583695   0.079399   \n",
       "9051    20481.373047  6.541937       2  341725.980849  251.583695   0.059935   \n",
       "9052    18504.693359  6.787939       2  341725.980849  251.583695   0.054151   \n",
       "9053    19626.798828  6.252022       2  341725.980849  251.583695   0.057434   \n",
       "...              ...       ...     ...            ...         ...        ...   \n",
       "108236  11823.984375  0.752936       2   28535.776242    1.648858   0.414357   \n",
       "108237  13798.040039  0.892335       2   28535.776242    1.648858   0.483535   \n",
       "108238  18065.376953  1.142276       2   28535.776242    1.648858   0.633078   \n",
       "108239  17551.761719  1.102245       2   28535.776242    1.648858   0.615079   \n",
       "108240  15780.050781  0.995648       2   28535.776242    1.648858   0.552992   \n",
       "\n",
       "        rms_ratio  seizure_number  \n",
       "9049     0.025010               7  \n",
       "9050     0.029666               7  \n",
       "9051     0.026003               7  \n",
       "9052     0.026981               7  \n",
       "9053     0.024851               7  \n",
       "...           ...             ...  \n",
       "108236   0.456641              47  \n",
       "108237   0.541184              47  \n",
       "108238   0.692768              47  \n",
       "108239   0.668490              47  \n",
       "108240   0.603841              47  \n",
       "\n",
       "[406 rows x 216 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FP1-F7-0</th>\n      <th>FP1-F7-1</th>\n      <th>FP1-F7-2</th>\n      <th>FP1-F7-3</th>\n      <th>FP1-F7-4</th>\n      <th>FP1-F7-5</th>\n      <th>FP1-F7-6</th>\n      <th>FP1-F7-7</th>\n      <th>FP1-F7-8</th>\n      <th>F7-T7-0</th>\n      <th>...</th>\n      <th>T8-P8-1-8</th>\n      <th>patient</th>\n      <th>sum</th>\n      <th>rms</th>\n      <th>target</th>\n      <th>mean_sum</th>\n      <th>mean_rms</th>\n      <th>sum_ratio</th>\n      <th>rms_ratio</th>\n      <th>seizure_number</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9049</th>\n      <td>0.487906</td>\n      <td>0.294157</td>\n      <td>0.062645</td>\n      <td>0.243455</td>\n      <td>0.061901</td>\n      <td>0.003636</td>\n      <td>0.013767</td>\n      <td>0.003427</td>\n      <td>733.779602</td>\n      <td>0.385181</td>\n      <td>...</td>\n      <td>1923.753174</td>\n      <td>1.0</td>\n      <td>28861.935547</td>\n      <td>6.292221</td>\n      <td>2</td>\n      <td>341725.980849</td>\n      <td>251.583695</td>\n      <td>0.084459</td>\n      <td>0.025010</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>9050</th>\n      <td>0.492928</td>\n      <td>0.287013</td>\n      <td>0.072026</td>\n      <td>0.238879</td>\n      <td>0.060910</td>\n      <td>0.002932</td>\n      <td>0.012587</td>\n      <td>0.004014</td>\n      <td>711.672302</td>\n      <td>0.415166</td>\n      <td>...</td>\n      <td>2015.595825</td>\n      <td>1.0</td>\n      <td>27132.595703</td>\n      <td>7.463470</td>\n      <td>2</td>\n      <td>341725.980849</td>\n      <td>251.583695</td>\n      <td>0.079399</td>\n      <td>0.029666</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>9051</th>\n      <td>0.406936</td>\n      <td>0.237590</td>\n      <td>0.078928</td>\n      <td>0.220020</td>\n      <td>0.104659</td>\n      <td>0.004607</td>\n      <td>0.020451</td>\n      <td>0.006975</td>\n      <td>398.291138</td>\n      <td>0.365368</td>\n      <td>...</td>\n      <td>1690.714233</td>\n      <td>1.0</td>\n      <td>20481.373047</td>\n      <td>6.541937</td>\n      <td>2</td>\n      <td>341725.980849</td>\n      <td>251.583695</td>\n      <td>0.059935</td>\n      <td>0.026003</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>9052</th>\n      <td>0.377607</td>\n      <td>0.232304</td>\n      <td>0.089268</td>\n      <td>0.232302</td>\n      <td>0.118813</td>\n      <td>0.004778</td>\n      <td>0.024522</td>\n      <td>0.006443</td>\n      <td>364.721436</td>\n      <td>0.288228</td>\n      <td>...</td>\n      <td>1452.021973</td>\n      <td>1.0</td>\n      <td>18504.693359</td>\n      <td>6.787939</td>\n      <td>2</td>\n      <td>341725.980849</td>\n      <td>251.583695</td>\n      <td>0.054151</td>\n      <td>0.026981</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>9053</th>\n      <td>0.464701</td>\n      <td>0.204894</td>\n      <td>0.068319</td>\n      <td>0.203080</td>\n      <td>0.098251</td>\n      <td>0.004644</td>\n      <td>0.023169</td>\n      <td>0.005235</td>\n      <td>448.785583</td>\n      <td>0.327284</td>\n      <td>...</td>\n      <td>1480.842529</td>\n      <td>1.0</td>\n      <td>19626.798828</td>\n      <td>6.252022</td>\n      <td>2</td>\n      <td>341725.980849</td>\n      <td>251.583695</td>\n      <td>0.057434</td>\n      <td>0.024851</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>108236</th>\n      <td>0.350583</td>\n      <td>0.335095</td>\n      <td>0.148207</td>\n      <td>0.243422</td>\n      <td>0.072715</td>\n      <td>0.004027</td>\n      <td>0.018495</td>\n      <td>0.004422</td>\n      <td>443.893036</td>\n      <td>0.310951</td>\n      <td>...</td>\n      <td>356.422028</td>\n      <td>14.0</td>\n      <td>11823.984375</td>\n      <td>0.752936</td>\n      <td>2</td>\n      <td>28535.776242</td>\n      <td>1.648858</td>\n      <td>0.414357</td>\n      <td>0.456641</td>\n      <td>47</td>\n    </tr>\n    <tr>\n      <th>108237</th>\n      <td>0.257892</td>\n      <td>0.372992</td>\n      <td>0.143660</td>\n      <td>0.229055</td>\n      <td>0.104612</td>\n      <td>0.005055</td>\n      <td>0.022896</td>\n      <td>0.004901</td>\n      <td>440.472992</td>\n      <td>0.233394</td>\n      <td>...</td>\n      <td>465.785309</td>\n      <td>14.0</td>\n      <td>13798.040039</td>\n      <td>0.892335</td>\n      <td>2</td>\n      <td>28535.776242</td>\n      <td>1.648858</td>\n      <td>0.483535</td>\n      <td>0.541184</td>\n      <td>47</td>\n    </tr>\n    <tr>\n      <th>108238</th>\n      <td>0.228357</td>\n      <td>0.377390</td>\n      <td>0.137621</td>\n      <td>0.221662</td>\n      <td>0.114477</td>\n      <td>0.006110</td>\n      <td>0.024464</td>\n      <td>0.004368</td>\n      <td>510.064880</td>\n      <td>0.216920</td>\n      <td>...</td>\n      <td>505.763641</td>\n      <td>14.0</td>\n      <td>18065.376953</td>\n      <td>1.142276</td>\n      <td>2</td>\n      <td>28535.776242</td>\n      <td>1.648858</td>\n      <td>0.633078</td>\n      <td>0.692768</td>\n      <td>47</td>\n    </tr>\n    <tr>\n      <th>108239</th>\n      <td>0.227919</td>\n      <td>0.336646</td>\n      <td>0.152785</td>\n      <td>0.235380</td>\n      <td>0.128835</td>\n      <td>0.008861</td>\n      <td>0.032484</td>\n      <td>0.006166</td>\n      <td>480.779297</td>\n      <td>0.168591</td>\n      <td>...</td>\n      <td>505.745270</td>\n      <td>14.0</td>\n      <td>17551.761719</td>\n      <td>1.102245</td>\n      <td>2</td>\n      <td>28535.776242</td>\n      <td>1.648858</td>\n      <td>0.615079</td>\n      <td>0.668490</td>\n      <td>47</td>\n    </tr>\n    <tr>\n      <th>108240</th>\n      <td>0.215618</td>\n      <td>0.250228</td>\n      <td>0.161290</td>\n      <td>0.257148</td>\n      <td>0.178950</td>\n      <td>0.013886</td>\n      <td>0.049401</td>\n      <td>0.008039</td>\n      <td>420.604675</td>\n      <td>0.160744</td>\n      <td>...</td>\n      <td>480.679596</td>\n      <td>14.0</td>\n      <td>15780.050781</td>\n      <td>0.995648</td>\n      <td>2</td>\n      <td>28535.776242</td>\n      <td>1.648858</td>\n      <td>0.552992</td>\n      <td>0.603841</td>\n      <td>47</td>\n    </tr>\n  </tbody>\n</table>\n<p>406 rows × 216 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 507
    }
   ],
   "source": [
    "interictal_test_df=pd.DataFrame(data=X_interictal_test)\n",
    "interictal_test_df['target']=y_interictal_test\n",
    "interictal_test_df\n",
    "# test_df=test_df.append(interictal_test_df, ignore_index=True)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate((X_interictal_train, X_preictal_train))\n",
    "y_train = np.concatenate((y_interictal_train, y_preictal_train))\n",
    "X_test = np.array(test_df[test_df.drop(['target', 'seizure_number'], axis=1).columns]).astype('float32')\n",
    "y_test  =np.array(test_df['target']).astype('float32')\n",
    "X_test = np.concatenate((X_test, X_interictal_test))\n",
    "y_test  =np.concatenate((y_test, y_interictal_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[4.8790631e-01, 2.9415703e-01, 6.2645197e-02, ..., 2.5158369e+02,\n",
       "        8.4459297e-02, 2.5010446e-02],\n",
       "       [4.9292761e-01, 2.8701285e-01, 7.2025925e-02, ..., 2.5158369e+02,\n",
       "        7.9398692e-02, 2.9665951e-02],\n",
       "       [4.0693572e-01, 2.3758979e-01, 7.8927673e-02, ..., 2.5158369e+02,\n",
       "        5.9935078e-02, 2.6003024e-02],\n",
       "       ...,\n",
       "       [1.8161055e-02, 1.2019242e-01, 8.0024570e-02, ..., 4.4369327e+02,\n",
       "        7.8268722e-02, 2.4852756e-02],\n",
       "       [7.4824855e-02, 7.5760946e-02, 5.2212620e-01, ..., 5.8796444e+01,\n",
       "        5.5209942e-02, 2.6588451e-02],\n",
       "       [4.3106064e-02, 1.3040492e-01, 6.2795825e-02, ..., 2.2593469e+02,\n",
       "        2.4539391e-02, 4.3541770e-03]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 509
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(4674, 214)\n(679, 214)\n(4674,)\n(679,)\n"
     ]
    }
   ],
   "source": [
    "X_train=np.array(X_train).astype('float32')\n",
    "X_test=np.array( X_test).astype('float32')\n",
    "y_train=np.array(y_train).astype('float32')\n",
    "y_test=np.array( y_test).astype('float32')\n",
    "\n",
    "X_train_shape =X_train.shape\n",
    "X_test_shape = X_test.shape\n",
    "y_train_shape =y_train.shape \n",
    "y_test_shape = y_test.shape\n",
    "print(X_train_shape)\n",
    "print(X_test_shape)\n",
    "print(y_train_shape)\n",
    "print(y_test_shape)"
   ]
  },
  {
   "source": [
    "### Normalization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# scaler = MinMaxScaler()\n",
    "# scaler.fit(X_train)\n",
    "# scaler.transform(X_train)\n",
    "# scaler.fit(X_test)\n",
    "# scaler.transform(X_test)"
   ]
  },
  {
   "source": [
    "### PCA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# pca = PCA(n_components=100)\n",
    "# X_train2=pca.fit_transform(X_train)\n",
    "# X_test2=pca.transform(X_test)"
   ]
  },
  {
   "source": [
    "### training the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost: 150.0\n",
    "weight_dict: {0: 1, 2: 10}"
   ]
  },
  {
   "source": [
    "before = datetime.now()\n",
    "before_time =before.strftime(\"%H:%M:%S\")\n",
    "print(before_time)\n",
    "\n",
    "clf = SVC(C=2000,kernel='rbf', random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "trainAcc = clf.score(X_train, y_train)\n",
    "testAcc = clf.score(X_test, y_test)\n",
    "print(\"**SVM Results:**\")\n",
    "print(\"Training Accuracy: %d\"%(trainAcc*100)+\"%\")\n",
    "print(\"Testing Accuracy: %d\"%(testAcc *100)+\"%\")\n",
    "\n",
    "after = datetime.now()\n",
    "after_time =after.strftime(\"%H:%M:%S\")\n",
    "print(after_time)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 534,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "18:54:54\n",
      "**SVM Results:**\n",
      "Training Accuracy: 70%\n",
      "Testing Accuracy: 66%\n",
      "18:55:05\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['my_models/temporal2000Cundersample75f1.pkl']"
      ]
     },
     "metadata": {},
     "execution_count": 535
    }
   ],
   "source": [
    "# import joblib\n",
    "\n",
    "    # estimator = joblib.load(\"/my_models/%s.pkl\"%dataset_name)\n",
    "    # print \"using trained model\"\n",
    "\n",
    "# print (\"saving new model\")\n",
    "# joblib.dump(clf,\"my_models/temporal2000Cundersample75f1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_clf = joblib.load(\"my_models/SVM_blanced_chb04.pkl\")\n",
    "# y_pred=loaded_clf.predict(X_test)\n",
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'C': 2000,\n",
       " 'break_ties': False,\n",
       " 'cache_size': 200,\n",
       " 'class_weight': None,\n",
       " 'coef0': 0.0,\n",
       " 'decision_function_shape': 'ovr',\n",
       " 'degree': 3,\n",
       " 'gamma': 'scale',\n",
       " 'kernel': 'rbf',\n",
       " 'max_iter': -1,\n",
       " 'probability': False,\n",
       " 'random_state': 42,\n",
       " 'shrinking': True,\n",
       " 'tol': 0.001,\n",
       " 'verbose': False}"
      ]
     },
     "metadata": {},
     "execution_count": 537
    }
   ],
   "source": [
    "clf.get_params(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TN:139, FP:134, FN:96, TP:310\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = sklearn.metrics.confusion_matrix(y_test, y_pred).ravel()\n",
    "print(\"TN:{}, FP:{}, FN:{}, TP:{}\".format(tn, fp, fn, tp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "specificity= 0.5091575091575091 , sensitivity= 0.7635467980295566, f1= 0.7294117647058822\n"
     ]
    }
   ],
   "source": [
    "specificity=(tn)/(tn+fp)\n",
    "sensitivity=(tp)/(tp+fn)\n",
    "f1_score=sklearn.metrics.f1_score(y_test, y_pred, pos_label=2)\n",
    "\n",
    "print('specificity= {} , sensitivity= {}, f1= {}'.format(specificity, sensitivity, f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "C: 2000, W: None\nX size =(110462, 208), y size = (110462,)\ninterictal size =(2725, 216), preictal size = (2222, 216)\ntrain size =(4674, 214), test size = (679, 214)\nTraining Accuracy: 70%\nTesting Accuracy: 66%\nTN:139, FP:134, FN:96, TP:310\nspecificity= 0.5091575091575091 , sensitivity= 0.7635467980295566, f1= 0.7294117647058822\n"
     ]
    }
   ],
   "source": [
    "print('C: {}, W: {}'.format(clf.get_params(deep=True)['C'], clf.get_params(deep=True)['class_weight']))\n",
    "print('X size ={}, y size = {}'.format(X_shape, y_shape))\n",
    "print('interictal size ={}, preictal size = {}'.format(interictal_shape, preictal_shape))\n",
    "print('train size ={}, test size = {}'.format(X_train_shape, X_test_shape))\n",
    "\n",
    "print(\"Training Accuracy: %d\"%(trainAcc*100)+\"%\")\n",
    "print(\"Testing Accuracy: %d\"%(testAcc *100)+\"%\")\n",
    "print(\"TN:{}, FP:{}, FN:{}, TP:{}\".format(tn, fp, fn, tp))\n",
    "print('specificity= {} , sensitivity= {}, f1= {}'.format(specificity, sensitivity, f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2021-06-06 18:55:06.695133\n",
      "**Random Forest Results:**\n",
      "Training Accuracy: 99%\n",
      "Testing Accuracy: 58%\n",
      "0:00:02.433489\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_start = datetime.now()\n",
    "print(rf_start)\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=50, max_depth=20, random_state=70)\n",
    "rf.fit(X_train, y_train)\n",
    "trainAcc=rf.score(X_train, y_train)\n",
    "testAcc=rf.score(X_test, y_test)\n",
    "print(\"**Random Forest Results:**\")\n",
    "print(\"Training Accuracy: %d\"%(trainAcc*100)+\"%\")\n",
    "print(\"Testing Accuracy: %d\"%(testAcc *100)+\"%\")\n",
    "\n",
    "rf_finish = datetime.now()\n",
    "rf_time =(rf_finish-rf_start)\n",
    "print(rf_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_y_pred=rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TN:233, FP:40, FN:239, TP:167\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = sklearn.metrics.confusion_matrix(y_test, rf_y_pred).ravel()\n",
    "print(\"TN:{}, FP:{}, FN:{}, TP:{}\".format(tn, fp, fn, tp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "specificity= 0.8534798534798534 , sensitivity= 0.41133004926108374, f1= 0.5448613376835237\n"
     ]
    }
   ],
   "source": [
    "specificity=(tn)/(tn+fp)\n",
    "sensitivity=(tp)/(tp+fn)\n",
    "f1_score=sklearn.metrics.f1_score(y_test, rf_y_pred, pos_label=2)\n",
    "\n",
    "print('specificity= {} , sensitivity= {}, f1= {}'.format(specificity, sensitivity, f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X size =(110462, 208), y size = (110462,)\ninterictal size =(2725, 216), preictal size = (2222, 216)\ntrain size =(4674, 214), test size = (679, 214)\nTraining Accuracy: 99%\nTesting Accuracy: 58%\nTN:233, FP:40, FN:239, TP:167\nspecificity= 0.8534798534798534 , sensitivity= 0.41133004926108374, f1= 0.5448613376835237\n"
     ]
    }
   ],
   "source": [
    "print('X size ={}, y size = {}'.format(X_shape, y_shape))\n",
    "print('interictal size ={}, preictal size = {}'.format(interictal_shape, preictal_shape))\n",
    "print('train size ={}, test size = {}'.format(X_train_shape, X_test_shape))\n",
    "\n",
    "print(\"Training Accuracy: %d\"%(trainAcc*100)+\"%\")\n",
    "print(\"Testing Accuracy: %d\"%(testAcc *100)+\"%\")\n",
    "print(\"TN:{}, FP:{}, FN:{}, TP:{}\".format(tn, fp, fn, tp))\n",
    "print('specificity= {} , sensitivity= {}, f1= {}'.format(specificity, sensitivity, f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def f_importances(coef, names):\n",
    "#     imp = coef\n",
    "#     imp,names = zip(*sorted(zip(imp,names)))\n",
    "#     plt.barh(range(len(names)), imp, align='center')\n",
    "#     plt.yticks(range(len(names)), names)\n",
    "#     plt.show()\n",
    "# f_importances(clf.coef_, generate_column_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [FP1-F7-0, FP1-F7-1, FP1-F7-2, FP1-F7-3, FP1-F7-4, FP1-F7-5, FP1-F7-6, FP1-F7-7, FP1-F7-8, F7-T7-0, F7-T7-1, F7-T7-2, F7-T7-3, F7-T7-4, F7-T7-5, F7-T7-6, F7-T7-7, F7-T7-8, T7-P7-0, T7-P7-1, T7-P7-2, T7-P7-3, T7-P7-4, T7-P7-5, T7-P7-6, T7-P7-7, T7-P7-8, P7-O1-0, P7-O1-1, P7-O1-2, P7-O1-3, P7-O1-4, P7-O1-5, P7-O1-6, P7-O1-7, P7-O1-8, FP1-F3-0, FP1-F3-1, FP1-F3-2, FP1-F3-3, FP1-F3-4, FP1-F3-5, FP1-F3-6, FP1-F3-7, FP1-F3-8, F3-C3-0, F3-C3-1, F3-C3-2, F3-C3-3, F3-C3-4, F3-C3-5, F3-C3-6, F3-C3-7, F3-C3-8, C3-P3-0, C3-P3-1, C3-P3-2, C3-P3-3, C3-P3-4, C3-P3-5, C3-P3-6, C3-P3-7, C3-P3-8, P3-O1-0, P3-O1-1, P3-O1-2, P3-O1-3, P3-O1-4, P3-O1-5, P3-O1-6, P3-O1-7, P3-O1-8, FP2-F4-0, FP2-F4-1, FP2-F4-2, FP2-F4-3, FP2-F4-4, FP2-F4-5, FP2-F4-6, FP2-F4-7, FP2-F4-8, F4-C4-0, F4-C4-1, F4-C4-2, F4-C4-3, F4-C4-4, F4-C4-5, F4-C4-6, F4-C4-7, F4-C4-8, C4-P4-0, C4-P4-1, C4-P4-2, C4-P4-3, C4-P4-4, C4-P4-5, C4-P4-6, C4-P4-7, C4-P4-8, P4-O2-0, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 216 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FP1-F7-0</th>\n      <th>FP1-F7-1</th>\n      <th>FP1-F7-2</th>\n      <th>FP1-F7-3</th>\n      <th>FP1-F7-4</th>\n      <th>FP1-F7-5</th>\n      <th>FP1-F7-6</th>\n      <th>FP1-F7-7</th>\n      <th>FP1-F7-8</th>\n      <th>F7-T7-0</th>\n      <th>...</th>\n      <th>T8-P8-1-8</th>\n      <th>patient</th>\n      <th>sum</th>\n      <th>rms</th>\n      <th>target</th>\n      <th>mean_sum</th>\n      <th>mean_rms</th>\n      <th>sum_ratio</th>\n      <th>rms_ratio</th>\n      <th>seizure_number</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n<p>0 rows × 216 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 548
    }
   ],
   "source": [
    "# df10=pd.DataFrame(data=X_10, columns=generate_column_names())\n",
    "df10=df[df['patient']==11]\n",
    "df10=df10[(df10['target']==2) | (df10['target']==0) ]\n",
    "# df10['target']=y_10\n",
    "# print(df10.shape)\n",
    "# df10=df10.dropna()\n",
    "# print(df10.shape)\n",
    "# df10.reset_index(drop=True, inplace=True)\n",
    "# df10=df10[(df10['target']==0) | (df10['target']==2)]\n",
    "# print(df10['target'].max())\n",
    "# df10=df10[(df10['patient']==10) ]\n",
    "df10\n",
    "# X_10_test  =np.array(test_df[df.columns[-1]]).astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "metadata": {},
     "execution_count": 549
    }
   ],
   "source": [
    "df10['patient'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [FP1-F7-0, FP1-F7-1, FP1-F7-2, FP1-F7-3, FP1-F7-4, FP1-F7-5, FP1-F7-6, FP1-F7-7, FP1-F7-8, F7-T7-0, F7-T7-1, F7-T7-2, F7-T7-3, F7-T7-4, F7-T7-5, F7-T7-6, F7-T7-7, F7-T7-8, T7-P7-0, T7-P7-1, T7-P7-2, T7-P7-3, T7-P7-4, T7-P7-5, T7-P7-6, T7-P7-7, T7-P7-8, P7-O1-0, P7-O1-1, P7-O1-2, P7-O1-3, P7-O1-4, P7-O1-5, P7-O1-6, P7-O1-7, P7-O1-8, FP1-F3-0, FP1-F3-1, FP1-F3-2, FP1-F3-3, FP1-F3-4, FP1-F3-5, FP1-F3-6, FP1-F3-7, FP1-F3-8, F3-C3-0, F3-C3-1, F3-C3-2, F3-C3-3, F3-C3-4, F3-C3-5, F3-C3-6, F3-C3-7, F3-C3-8, C3-P3-0, C3-P3-1, C3-P3-2, C3-P3-3, C3-P3-4, C3-P3-5, C3-P3-6, C3-P3-7, C3-P3-8, P3-O1-0, P3-O1-1, P3-O1-2, P3-O1-3, P3-O1-4, P3-O1-5, P3-O1-6, P3-O1-7, P3-O1-8, FP2-F4-0, FP2-F4-1, FP2-F4-2, FP2-F4-3, FP2-F4-4, FP2-F4-5, FP2-F4-6, FP2-F4-7, FP2-F4-8, F4-C4-0, F4-C4-1, F4-C4-2, F4-C4-3, F4-C4-4, F4-C4-5, F4-C4-6, F4-C4-7, F4-C4-8, C4-P4-0, C4-P4-1, C4-P4-2, C4-P4-3, C4-P4-4, C4-P4-5, C4-P4-6, C4-P4-7, C4-P4-8, P4-O2-0, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 215 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FP1-F7-0</th>\n      <th>FP1-F7-1</th>\n      <th>FP1-F7-2</th>\n      <th>FP1-F7-3</th>\n      <th>FP1-F7-4</th>\n      <th>FP1-F7-5</th>\n      <th>FP1-F7-6</th>\n      <th>FP1-F7-7</th>\n      <th>FP1-F7-8</th>\n      <th>F7-T7-0</th>\n      <th>...</th>\n      <th>T8-P8-1-7</th>\n      <th>T8-P8-1-8</th>\n      <th>patient</th>\n      <th>sum</th>\n      <th>rms</th>\n      <th>mean_sum</th>\n      <th>mean_rms</th>\n      <th>sum_ratio</th>\n      <th>rms_ratio</th>\n      <th>seizure_number</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n<p>0 rows × 215 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 550
    }
   ],
   "source": [
    "df10[df10.drop('target', axis=1).columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_10_test  =np.array(df10.drop('target', axis=1)).astype('float32')\n",
    "y_10_test  =np.array(df10['target']).astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 215)) while a minimum of 1 is required.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-552-181a43039a3a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_10\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_10_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest_10\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    622\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 624\u001b[1;33m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    625\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    340\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mndarray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m         \"\"\"\n\u001b[1;32m--> 342\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    343\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_validate_for_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    473\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m             X = check_array(X, accept_sparse='csr', dtype=np.float64,\n\u001b[1;32m--> 475\u001b[1;33m                             order=\"C\", accept_large_sparse=False)\n\u001b[0m\u001b[0;32m    476\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    670\u001b[0m                              \u001b[1;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m                              % (n_samples, array.shape, ensure_min_samples,\n\u001b[1;32m--> 672\u001b[1;33m                                 context))\n\u001b[0m\u001b[0;32m    673\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_features\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 215)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "test_10=clf.predict(X_10_test)\n",
    "test_10.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9496551724137932"
      ]
     },
     "metadata": {},
     "execution_count": 344
    }
   ],
   "source": [
    "tes_10_score = clf.score(X_10_test, y_10_test)\n",
    "tes_10_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TN:10991, FP:465, FN:119, TP:25\nspecificity= 0.9594099162011173 , sensitivity= 0.1736111111111111, f1= 0.07886435331230283\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = sklearn.metrics.confusion_matrix(y_10_test, test_10).ravel()\n",
    "print(\"TN:{}, FP:{}, FN:{}, TP:{}\".format(tn, fp, fn, tp))\n",
    "specificity=(tn)/(tn+fp)\n",
    "sensitivity=(tp)/(tp+fn)\n",
    "f1_score=sklearn.metrics.f1_score(y_10_test, test_10, pos_label=2)\n",
    "\n",
    "print('specificity= {} , sensitivity= {}, f1= {}'.format(specificity, sensitivity, f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       real  predicted\n",
       "0       0.0        0.0\n",
       "1       0.0        0.0\n",
       "2       0.0        0.0\n",
       "3       0.0        0.0\n",
       "4       0.0        0.0\n",
       "...     ...        ...\n",
       "11595   2.0        0.0\n",
       "11596   2.0        0.0\n",
       "11597   2.0        0.0\n",
       "11598   2.0        0.0\n",
       "11599   2.0        0.0\n",
       "\n",
       "[11600 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>real</th>\n      <th>predicted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>11595</th>\n      <td>2.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>11596</th>\n      <td>2.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>11597</th>\n      <td>2.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>11598</th>\n      <td>2.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>11599</th>\n      <td>2.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>11600 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 346
    }
   ],
   "source": [
    "df_results16=pd.DataFrame({'real':y_10_test, 'predicted':test_10})\n",
    "df_results16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(ser):\n",
    "    window=5\n",
    "    i=0\n",
    "    while i < len(ser)-window:\n",
    "        if ser[i]==ser[i+window]:\n",
    "            ser[i:i+window]=ser[i]\n",
    "        i+=1\n",
    "    return np.array(ser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "def smooth_mode(ser):\n",
    "    window=50\n",
    "    i=0\n",
    "    while i < len(ser)-window:\n",
    "        ser[i:i+window]=statistics.mode(ser[i:i+window])\n",
    "        i+=window\n",
    "    return np.array(ser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 349
    }
   ],
   "source": [
    "smooth_pred=smooth(test_10)\n",
    "smooth_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TN:11310, FP:146, FN:133, TP:11\nspecificity= 0.9872555865921788 , sensitivity= 0.0763888888888889, f1= 0.07308970099667775\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = sklearn.metrics.confusion_matrix(y_10_test, smooth_pred).ravel()\n",
    "print(\"TN:{}, FP:{}, FN:{}, TP:{}\".format(tn, fp, fn, tp))\n",
    "specificity=(tn)/(tn+fp)\n",
    "sensitivity=(tp)/(tp+fn)\n",
    "f1_score=sklearn.metrics.f1_score(y_10_test, smooth_pred, pos_label=2)\n",
    "\n",
    "print('specificity= {} , sensitivity= {}, f1= {}'.format(specificity, sensitivity, f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TN:11406, FP:50, FN:138, TP:6\nspecificity= 0.9956354748603352 , sensitivity= 0.041666666666666664, f1= 0.06\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = sklearn.metrics.confusion_matrix(y_10_test, smooth_mode(test_10)).ravel()\n",
    "print(\"TN:{}, FP:{}, FN:{}, TP:{}\".format(tn, fp, fn, tp))\n",
    "specificity=(tn)/(tn+fp)\n",
    "sensitivity=(tp)/(tp+fn)\n",
    "f1_score=sklearn.metrics.f1_score(y_10_test, smooth_mode(test_10), pos_label=2)\n",
    "\n",
    "print('specificity= {} , sensitivity= {}, f1= {}'.format(specificity, sensitivity, f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-352-4f76a9dad686>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "source": [
    "### grid search"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "balance = [{0:10,2:1}, {0:1,2:1}, {0:1,2:10}, {0:1,2:15}, {0:1,2:20}]\n",
    "costs=[1.0,10.0,100.0, 150.0,1000.0]\n",
    "# balance = [{0:1,2:10}, {0:1,2:15}]\n",
    "# costs=[1.0]\n",
    "param_grid = dict(C=costs, class_weight=balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_keys(['explained_variance', 'r2', 'max_error', 'neg_median_absolute_error', 'neg_mean_absolute_error', 'neg_mean_absolute_percentage_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'neg_root_mean_squared_error', 'neg_mean_poisson_deviance', 'neg_mean_gamma_deviance', 'accuracy', 'top_k_accuracy', 'roc_auc', 'roc_auc_ovr', 'roc_auc_ovo', 'roc_auc_ovr_weighted', 'roc_auc_ovo_weighted', 'balanced_accuracy', 'average_precision', 'neg_log_loss', 'neg_brier_score', 'adjusted_rand_score', 'rand_score', 'homogeneity_score', 'completeness_score', 'v_measure_score', 'mutual_info_score', 'adjusted_mutual_info_score', 'normalized_mutual_info_score', 'fowlkes_mallows_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'jaccard', 'jaccard_macro', 'jaccard_micro', 'jaccard_samples', 'jaccard_weighted'])"
      ]
     },
     "metadata": {},
     "execution_count": 147
    }
   ],
   "source": [
    "sklearn.metrics.SCORERS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=1, random_state=1)\n",
    "grid = GridSearchCV(estimator=clf, param_grid=param_grid, n_jobs=-1, cv=cv, scoring='f1_macro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best: 0.548936 using {'C': 1000.0, 'class_weight': {0: 1, 2: 1}}\n0.464987 (0.000025) with: {'C': 1.0, 'class_weight': {0: 10, 2: 1}}\n0.464987 (0.000025) with: {'C': 1.0, 'class_weight': {0: 1, 2: 1}}\n0.217273 (0.004215) with: {'C': 1.0, 'class_weight': {0: 1, 2: 10}}\n0.202093 (0.005248) with: {'C': 1.0, 'class_weight': {0: 1, 2: 15}}\n0.193375 (0.004963) with: {'C': 1.0, 'class_weight': {0: 1, 2: 20}}\n0.467381 (0.001471) with: {'C': 10.0, 'class_weight': {0: 10, 2: 1}}\n0.473319 (0.003141) with: {'C': 10.0, 'class_weight': {0: 1, 2: 1}}\n0.269558 (0.003700) with: {'C': 10.0, 'class_weight': {0: 1, 2: 10}}\n0.240071 (0.005545) with: {'C': 10.0, 'class_weight': {0: 1, 2: 15}}\n0.219372 (0.005653) with: {'C': 10.0, 'class_weight': {0: 1, 2: 20}}\n0.474830 (0.001837) with: {'C': 100.0, 'class_weight': {0: 10, 2: 1}}\n0.491107 (0.004591) with: {'C': 100.0, 'class_weight': {0: 1, 2: 1}}\n0.326736 (0.007160) with: {'C': 100.0, 'class_weight': {0: 1, 2: 10}}\n0.263315 (0.005673) with: {'C': 100.0, 'class_weight': {0: 1, 2: 15}}\n0.242643 (0.005273) with: {'C': 100.0, 'class_weight': {0: 1, 2: 20}}\n0.475986 (0.002058) with: {'C': 150.0, 'class_weight': {0: 10, 2: 1}}\n0.498433 (0.005115) with: {'C': 150.0, 'class_weight': {0: 1, 2: 1}}\n0.335572 (0.006578) with: {'C': 150.0, 'class_weight': {0: 1, 2: 10}}\n0.268636 (0.006299) with: {'C': 150.0, 'class_weight': {0: 1, 2: 15}}\n0.247576 (0.005149) with: {'C': 150.0, 'class_weight': {0: 1, 2: 20}}\n0.491459 (0.006885) with: {'C': 1000.0, 'class_weight': {0: 10, 2: 1}}\n0.548936 (0.008327) with: {'C': 1000.0, 'class_weight': {0: 1, 2: 1}}\n0.360027 (0.005403) with: {'C': 1000.0, 'class_weight': {0: 1, 2: 10}}\n0.299736 (0.002228) with: {'C': 1000.0, 'class_weight': {0: 1, 2: 15}}\n0.284572 (0.003456) with: {'C': 1000.0, 'class_weight': {0: 1, 2: 20}}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}