{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37364bittfgpucondac099bc5da9054a33945af826af1262b9",
   "display_name": "Python 3.7.3 64-bit ('tf-gpu': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "4b3fe4e430614ae3e36b8912aa67966595d32d796c9f5e46d3c96e8e35c078a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import numpy.fft as fft\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats, signal\n",
    "from numpy import save, load\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "source": [
    "### read dataset X and Y"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "84\n",
      "(408, 208)\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "subject_id=1\n",
    "base_path = \"features/\"\n",
    "# edf_file_names = sorted(glob.glob(os.path.join(base_path, \"data_chb01/*.npy\".format(subject_id))))\n",
    "# files=len(edf_file_names)\n",
    "X=load('features/data_chb01/features_{}_00.npy'.format(subject_id))\n",
    "y=load('features/data_chb01/targets_{}_00.npy'.format(subject_id))\n",
    "for subject_id in range(1,2):\n",
    "    edf_file_names = sorted(glob.glob(os.path.join(base_path, \"data_chb{:02d}/*.npy\".format(subject_id))))\n",
    "    files=len(edf_file_names)\n",
    "    print(files)\n",
    "    print(X.shape)\n",
    "    start=0\n",
    "    if subject_id==1:\n",
    "        start=1\n",
    "    for fileno in range(start, files//2):\n",
    "        print(fileno)\n",
    "        X=np.concatenate((X, load('features/data_chb{:02d}/features_{}_{:02d}.npy'.format(subject_id, subject_id, fileno))))\n",
    "        y=np.concatenate((y, load('features/data_chb{:02d}/targets_{}_{:02d}.npy'.format(subject_id,subject_id, fileno))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(14584, 208) (14584,)\n"
     ]
    }
   ],
   "source": [
    "X_shape, y_shape = X.shape, y.shape\n",
    "print(X_shape, y_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(14584, 209)\n(14584, 209)\n"
     ]
    }
   ],
   "source": [
    "df=pd.DataFrame(data=X)\n",
    "df['target']=y\n",
    "print(df.shape)\n",
    "df=df.dropna()\n",
    "print(df.shape)"
   ]
  },
  {
   "source": [
    "### train test split"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(12188, 209) (975, 209)\n"
     ]
    }
   ],
   "source": [
    "df_interictal=df[df['target']==0]\n",
    "# print(df_interictal.shape)\n",
    "# df_interictal=df_interictal.sample(frac=0.7)\n",
    "df_preictal=df[df['target']==2]\n",
    "interictal_shape, preictal_shape = df_interictal.shape, df_preictal.shape\n",
    "print(df_interictal.shape, df_preictal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_interictal=np.array(df_interictal[df.columns[:-1]]).astype('float32')\n",
    "y_interictal=np.array(df_interictal['target']).astype('float32')\n",
    "X_preictal  =np.array(df_preictal[df.columns[:-1]]).astype('float32')\n",
    "y_preictal  =np.array(df_preictal['target']).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(12188, 208)\n(12188,)\n(975, 208)\n(975,)\n"
     ]
    }
   ],
   "source": [
    "print(X_interictal.shape)\n",
    "print(y_interictal.shape)\n",
    "print(X_preictal.shape)\n",
    "print(y_preictal.shape)"
   ]
  },
  {
   "source": [
    "### train test split"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_interictal_train, X_interictal_test, y_interictal_train, y_interictal_test =train_test_split(X_interictal,y_interictal,test_size=0.1, random_state=42)\n",
    "X_preictal_train, X_preictal_test, y_preictal_train, y_preictal_test=train_test_split(X_preictal, y_preictal,test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate((X_interictal_train, X_preictal_train))\n",
    "X_test = np.concatenate((X_interictal_test, X_preictal_test))\n",
    "y_train = np.concatenate((y_interictal_train, y_preictal_train))\n",
    "y_test = np.concatenate((y_interictal_test, y_preictal_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(11846, 208)\n(1317, 208)\n(11846,)\n(1317,)\n"
     ]
    }
   ],
   "source": [
    "X_train_shape =X_train.shape\n",
    "X_test_shape = X_test.shape\n",
    "y_train_shape =y_train.shape \n",
    "y_test_shape = y_test.shape\n",
    "print(X_train_shape)\n",
    "print(X_test_shape)\n",
    "print(y_train_shape)\n",
    "print(y_test_shape)"
   ]
  },
  {
   "source": [
    "### Normalization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[5.06899767e-02, 2.06566319e-01, 2.44740620e-02, ...,\n",
       "        3.16168010e-01, 8.29013061e-07, 1.00000000e+00],\n",
       "       [2.38289069e-02, 2.64799237e-01, 1.16495766e-01, ...,\n",
       "        1.51608899e-01, 2.98875057e-06, 0.00000000e+00],\n",
       "       [1.77743211e-02, 1.85866445e-01, 1.43353671e-01, ...,\n",
       "        1.70185298e-01, 9.69898610e-06, 6.66666627e-01],\n",
       "       ...,\n",
       "       [2.15109922e-02, 9.67502445e-02, 1.10558691e-02, ...,\n",
       "        4.12113339e-01, 1.13175914e-03, 1.00000000e+00],\n",
       "       [6.81196852e-03, 6.83366656e-02, 3.92035069e-03, ...,\n",
       "        4.36358184e-01, 4.70467021e-05, 6.66666627e-01],\n",
       "       [4.16661575e-02, 2.63042718e-01, 1.29583791e-01, ...,\n",
       "        1.59748152e-01, 5.48839807e-06, 3.33333343e-01]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# scaler = MinMaxScaler()\n",
    "# scaler.fit(X_train)\n",
    "# scaler.transform(X_train)\n",
    "# scaler.fit(X_test)\n",
    "# scaler.transform(X_test)"
   ]
  },
  {
   "source": [
    "### training the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost: 100.0\n",
    "weight_dict: {0: 1, 2: 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "02:52:32\n",
      "**SVM Results:**\n",
      "Training Accuracy: 87%\n",
      "Testing Accuracy: 88%\n",
      "02:53:07\n"
     ]
    }
   ],
   "source": [
    "before = datetime.now()\n",
    "before_time =before.strftime(\"%H:%M:%S\")\n",
    "print(before_time)\n",
    "\n",
    "clf = SVC(C=100, class_weight={0: 1, 2: 10})\n",
    "clf.fit(X_train, y_train)\n",
    "trainAcc = clf.score(X_train, y_train)\n",
    "testAcc = clf.score(X_test, y_test)\n",
    "print(\"**SVM Results:**\")\n",
    "print(\"Training Accuracy: %d\"%(trainAcc*100)+\"%\")\n",
    "print(\"Testing Accuracy: %d\"%(testAcc *100)+\"%\")\n",
    "\n",
    "after = datetime.now()\n",
    "after_time =after.strftime(\"%H:%M:%S\")\n",
    "print(after_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "saving new model\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['my_models/SVM_blanced_chb04.pkl']"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "    # estimator = joblib.load(\"/my_models/%s.pkl\"%dataset_name)\n",
    "    # print \"using trained model\"\n",
    "\n",
    "# print (\"saving new model\")\n",
    "# joblib.dump(clf,\"my_models/SVM_blanced_chb04.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_clf = joblib.load(\"my_models/SVM_blanced_chb04.pkl\")\n",
    "# y_pred=loaded_clf.predict(X_test)\n",
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'break_ties': False,\n",
       " 'cache_size': 200,\n",
       " 'class_weight': 'balanced',\n",
       " 'coef0': 0.0,\n",
       " 'decision_function_shape': 'ovr',\n",
       " 'degree': 3,\n",
       " 'gamma': 'scale',\n",
       " 'kernel': 'rbf',\n",
       " 'max_iter': -1,\n",
       " 'probability': False,\n",
       " 'random_state': None,\n",
       " 'shrinking': True,\n",
       " 'tol': 0.001,\n",
       " 'verbose': False}"
      ]
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "loaded_clf.get_params(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TN:1073, FP:146, FN:1, TP:97\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = sklearn.metrics.confusion_matrix(y_test, y_pred).ravel()\n",
    "print(\"TN:{}, FP:{}, FN:{}, TP:{}\".format(tn, fp, fn, tp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "specificity= 0.8802296964725185 , sensitivity= 0.9897959183673469\n"
     ]
    }
   ],
   "source": [
    "specificity=(tn)/(tn+fp)\n",
    "sensitivity=(tp)/(tp+fn)\n",
    "print('specificity= {} , sensitivity= {}'.format(specificity, sensitivity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X size =(14584, 208), y size = (14584,)\ninterictal size =(12188, 209), preictal size = (975, 209)\ntrain size =(11846, 208), test size = (1317, 208)\nTraining Accuracy: 87%\nTesting Accuracy: 88%\nTN:1073, FP:146, FN:1, TP:97\nspecificity= 0.8802296964725185 , sensitivity= 0.9897959183673469\n"
     ]
    }
   ],
   "source": [
    "print('X size ={}, y size = {}'.format(X_shape, y_shape))\n",
    "print('interictal size ={}, preictal size = {}'.format(interictal_shape, preictal_shape))\n",
    "print('train size ={}, test size = {}'.format(X_train_shape, X_test_shape))\n",
    "\n",
    "print(\"Training Accuracy: %d\"%(trainAcc*100)+\"%\")\n",
    "print(\"Testing Accuracy: %d\"%(testAcc *100)+\"%\")\n",
    "print(\"TN:{}, FP:{}, FN:{}, TP:{}\".format(tn, fp, fn, tp))\n",
    "print('specificity= {} , sensitivity= {}'.format(specificity, sensitivity))"
   ]
  },
  {
   "source": [
    "### grid search"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numpy import mean\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.model_selection import RepeatedStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balance = [{0:10,2:1}, {0:1,2:1}, {0:1,2:10}, {0:1,2:50}, {0:1,2:100}]\n",
    "# costs=[1.0,10.0,100.0]\n",
    "# param_grid = dict(C=costs, class_weight=balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=1, random_state=1)\n",
    "# grid = GridSearchCV(estimator=clf, param_grid=param_grid, n_jobs=-1, cv=cv, scoring='f1_weighted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best: 0.897876 using {'C': 100.0, 'class_weight': {0: 1, 2: 10}}\n0.890373 (0.000291) with: {'C': 1.0, 'class_weight': {0: 10, 2: 1}}\n0.890373 (0.000291) with: {'C': 1.0, 'class_weight': {0: 1, 2: 1}}\n0.749362 (0.010585) with: {'C': 1.0, 'class_weight': {0: 1, 2: 10}}\n0.651175 (0.005219) with: {'C': 1.0, 'class_weight': {0: 1, 2: 50}}\n0.631188 (0.009186) with: {'C': 1.0, 'class_weight': {0: 1, 2: 100}}\n0.890373 (0.000291) with: {'C': 10.0, 'class_weight': {0: 10, 2: 1}}\n0.890373 (0.000291) with: {'C': 10.0, 'class_weight': {0: 1, 2: 1}}\n0.855444 (0.006939) with: {'C': 10.0, 'class_weight': {0: 1, 2: 10}}\n0.784134 (0.010316) with: {'C': 10.0, 'class_weight': {0: 1, 2: 50}}\n0.750769 (0.007781) with: {'C': 10.0, 'class_weight': {0: 1, 2: 100}}\n0.890373 (0.000291) with: {'C': 100.0, 'class_weight': {0: 10, 2: 1}}\n0.890787 (0.000550) with: {'C': 100.0, 'class_weight': {0: 1, 2: 1}}\n0.897876 (0.006056) with: {'C': 100.0, 'class_weight': {0: 1, 2: 10}}\n0.849596 (0.008939) with: {'C': 100.0, 'class_weight': {0: 1, 2: 50}}\n0.821586 (0.009832) with: {'C': 100.0, 'class_weight': {0: 1, 2: 100}}\n"
     ]
    }
   ],
   "source": [
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# means = grid_result.cv_results_['mean_test_score']\n",
    "# stds = grid_result.cv_results_['std_test_score']\n",
    "# params = grid_result.cv_results_['params']\n",
    "# for mean, stdev, param in zip(means, stds, params):\n",
    "#     print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}