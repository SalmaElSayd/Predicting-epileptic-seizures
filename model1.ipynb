{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37364bittfgpucondac099bc5da9054a33945af826af1262b9",
   "display_name": "Python 3.7.3 64-bit ('tf-gpu': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "4b3fe4e430614ae3e36b8912aa67966595d32d796c9f5e46d3c96e8e35c078a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import numpy.fft as fft\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats, signal\n",
    "from numpy import save, load\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "source": [
    "### read dataset X and Y"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "84\n",
      "(408, 208)\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "72\n",
      "(14584, 208)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "76\n",
      "(27194, 208)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "24\n",
      "(40766, 208)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "subject_id=1\n",
    "base_path = \"features/\"\n",
    "# edf_file_names = sorted(glob.glob(os.path.join(base_path, \"data_chb01/*.npy\".format(subject_id))))\n",
    "# files=len(edf_file_names)\n",
    "X=load('features/data_chb01/features_{}_00.npy'.format(subject_id))\n",
    "y=load('features/data_chb01/targets_{}_00.npy'.format(subject_id))\n",
    "for subject_id in range(1,5):\n",
    "    edf_file_names = sorted(glob.glob(os.path.join(base_path, \"data_chb{:02d}/*.npy\".format(subject_id))))\n",
    "    files=len(edf_file_names)\n",
    "    print(files)\n",
    "    print(X.shape)\n",
    "    start=0\n",
    "    if subject_id==1:\n",
    "        start=1\n",
    "    for fileno in range(start, files//2):\n",
    "        print(fileno)\n",
    "        X=np.concatenate((X, load('features/data_chb{:02d}/features_{}_{:02d}.npy'.format(subject_id, subject_id, fileno))))\n",
    "        y=np.concatenate((y, load('features/data_chb{:02d}/targets_{}_{:02d}.npy'.format(subject_id,subject_id, fileno))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((55977, 208), (55977,))"
      ]
     },
     "metadata": {},
     "execution_count": 78
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target']=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(55977, 209)"
      ]
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(55977, 209)"
      ]
     },
     "metadata": {},
     "execution_count": 82
    }
   ],
   "source": [
    "df=df.dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "767   0.504019  0.161749  0.036241  0.087788  0.117071  0.010672  0.075750   \n",
       "768   0.397320  0.131061  0.041063  0.131679  0.127953  0.018591  0.123891   \n",
       "769   0.032970  0.067123  0.011638  0.045629  0.222607  0.082048  0.388199   \n",
       "770   0.013406  0.067360  0.010145  0.044625  0.228867  0.084977  0.397326   \n",
       "771   0.131704  0.184924  0.037553  0.238695  0.201855  0.023583  0.158190   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "9151  0.024826  0.082295  0.049787  0.065915  0.295219  0.086339  0.333806   \n",
       "9152  0.014045  0.083170  0.027623  0.031817  0.319929  0.085996  0.365671   \n",
       "9153  0.022369  0.120699  0.032243  0.047050  0.325650  0.063891  0.319887   \n",
       "9154  0.034451  0.159178  0.060282  0.076829  0.325747  0.056455  0.239840   \n",
       "9155  0.045098  0.168443  0.068901  0.114206  0.328712  0.044413  0.193135   \n",
       "\n",
       "             7           8         9  ...       199       200       201  \\\n",
       "767   0.006710   35.378636  0.340825  ...  0.282103  0.070293  0.147826   \n",
       "768   0.028443   41.653349  0.137482  ...  0.261818  0.062877  0.153241   \n",
       "769   0.149785  359.949214  0.022584  ...  0.168848  0.029229  0.121630   \n",
       "770   0.153293  342.790860  0.017106  ...  0.153139  0.030927  0.122526   \n",
       "771   0.023495   23.179371  0.198627  ...  0.184617  0.045994  0.168155   \n",
       "...        ...         ...       ...  ...       ...       ...       ...   \n",
       "9151  0.061814   56.292130  0.102190  ...  0.048700  0.042667  0.101418   \n",
       "9152  0.071750   75.450678  0.065839  ...  0.056387  0.047088  0.089704   \n",
       "9153  0.068213   45.941663  0.062855  ...  0.053789  0.052068  0.111783   \n",
       "9154  0.047217   27.680383  0.085372  ...  0.045370  0.047184  0.114786   \n",
       "9155  0.037093   23.489932  0.123299  ...  0.048632  0.049617  0.117277   \n",
       "\n",
       "           202       203       204       205        206  207  target  \n",
       "767   0.065048  0.009173  0.059392  0.005359  22.022274  1.0       3  \n",
       "768   0.082529  0.013847  0.073221  0.010040  24.051126  1.0       3  \n",
       "769   0.179059  0.042258  0.250080  0.064458  80.585204  1.0       3  \n",
       "770   0.180385  0.046731  0.282134  0.073164  88.751985  1.0       3  \n",
       "771   0.154820  0.037461  0.221824  0.067128  31.520675  1.0       3  \n",
       "...        ...       ...       ...       ...        ...  ...     ...  \n",
       "9151  0.115535  0.100833  0.517067  0.014999  97.952720  1.0       3  \n",
       "9152  0.125709  0.098840  0.507692  0.015631  98.250833  1.0       3  \n",
       "9153  0.115940  0.098990  0.508954  0.013975  97.544856  1.0       3  \n",
       "9154  0.107574  0.100771  0.512889  0.013147  94.074203  1.0       3  \n",
       "9155  0.105903  0.097607  0.498269  0.012862  97.610233  1.0       3  \n",
       "\n",
       "[1421 rows x 209 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>199</th>\n      <th>200</th>\n      <th>201</th>\n      <th>202</th>\n      <th>203</th>\n      <th>204</th>\n      <th>205</th>\n      <th>206</th>\n      <th>207</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>767</th>\n      <td>0.504019</td>\n      <td>0.161749</td>\n      <td>0.036241</td>\n      <td>0.087788</td>\n      <td>0.117071</td>\n      <td>0.010672</td>\n      <td>0.075750</td>\n      <td>0.006710</td>\n      <td>35.378636</td>\n      <td>0.340825</td>\n      <td>...</td>\n      <td>0.282103</td>\n      <td>0.070293</td>\n      <td>0.147826</td>\n      <td>0.065048</td>\n      <td>0.009173</td>\n      <td>0.059392</td>\n      <td>0.005359</td>\n      <td>22.022274</td>\n      <td>1.0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>768</th>\n      <td>0.397320</td>\n      <td>0.131061</td>\n      <td>0.041063</td>\n      <td>0.131679</td>\n      <td>0.127953</td>\n      <td>0.018591</td>\n      <td>0.123891</td>\n      <td>0.028443</td>\n      <td>41.653349</td>\n      <td>0.137482</td>\n      <td>...</td>\n      <td>0.261818</td>\n      <td>0.062877</td>\n      <td>0.153241</td>\n      <td>0.082529</td>\n      <td>0.013847</td>\n      <td>0.073221</td>\n      <td>0.010040</td>\n      <td>24.051126</td>\n      <td>1.0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>769</th>\n      <td>0.032970</td>\n      <td>0.067123</td>\n      <td>0.011638</td>\n      <td>0.045629</td>\n      <td>0.222607</td>\n      <td>0.082048</td>\n      <td>0.388199</td>\n      <td>0.149785</td>\n      <td>359.949214</td>\n      <td>0.022584</td>\n      <td>...</td>\n      <td>0.168848</td>\n      <td>0.029229</td>\n      <td>0.121630</td>\n      <td>0.179059</td>\n      <td>0.042258</td>\n      <td>0.250080</td>\n      <td>0.064458</td>\n      <td>80.585204</td>\n      <td>1.0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>770</th>\n      <td>0.013406</td>\n      <td>0.067360</td>\n      <td>0.010145</td>\n      <td>0.044625</td>\n      <td>0.228867</td>\n      <td>0.084977</td>\n      <td>0.397326</td>\n      <td>0.153293</td>\n      <td>342.790860</td>\n      <td>0.017106</td>\n      <td>...</td>\n      <td>0.153139</td>\n      <td>0.030927</td>\n      <td>0.122526</td>\n      <td>0.180385</td>\n      <td>0.046731</td>\n      <td>0.282134</td>\n      <td>0.073164</td>\n      <td>88.751985</td>\n      <td>1.0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>771</th>\n      <td>0.131704</td>\n      <td>0.184924</td>\n      <td>0.037553</td>\n      <td>0.238695</td>\n      <td>0.201855</td>\n      <td>0.023583</td>\n      <td>0.158190</td>\n      <td>0.023495</td>\n      <td>23.179371</td>\n      <td>0.198627</td>\n      <td>...</td>\n      <td>0.184617</td>\n      <td>0.045994</td>\n      <td>0.168155</td>\n      <td>0.154820</td>\n      <td>0.037461</td>\n      <td>0.221824</td>\n      <td>0.067128</td>\n      <td>31.520675</td>\n      <td>1.0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9151</th>\n      <td>0.024826</td>\n      <td>0.082295</td>\n      <td>0.049787</td>\n      <td>0.065915</td>\n      <td>0.295219</td>\n      <td>0.086339</td>\n      <td>0.333806</td>\n      <td>0.061814</td>\n      <td>56.292130</td>\n      <td>0.102190</td>\n      <td>...</td>\n      <td>0.048700</td>\n      <td>0.042667</td>\n      <td>0.101418</td>\n      <td>0.115535</td>\n      <td>0.100833</td>\n      <td>0.517067</td>\n      <td>0.014999</td>\n      <td>97.952720</td>\n      <td>1.0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>9152</th>\n      <td>0.014045</td>\n      <td>0.083170</td>\n      <td>0.027623</td>\n      <td>0.031817</td>\n      <td>0.319929</td>\n      <td>0.085996</td>\n      <td>0.365671</td>\n      <td>0.071750</td>\n      <td>75.450678</td>\n      <td>0.065839</td>\n      <td>...</td>\n      <td>0.056387</td>\n      <td>0.047088</td>\n      <td>0.089704</td>\n      <td>0.125709</td>\n      <td>0.098840</td>\n      <td>0.507692</td>\n      <td>0.015631</td>\n      <td>98.250833</td>\n      <td>1.0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>9153</th>\n      <td>0.022369</td>\n      <td>0.120699</td>\n      <td>0.032243</td>\n      <td>0.047050</td>\n      <td>0.325650</td>\n      <td>0.063891</td>\n      <td>0.319887</td>\n      <td>0.068213</td>\n      <td>45.941663</td>\n      <td>0.062855</td>\n      <td>...</td>\n      <td>0.053789</td>\n      <td>0.052068</td>\n      <td>0.111783</td>\n      <td>0.115940</td>\n      <td>0.098990</td>\n      <td>0.508954</td>\n      <td>0.013975</td>\n      <td>97.544856</td>\n      <td>1.0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>9154</th>\n      <td>0.034451</td>\n      <td>0.159178</td>\n      <td>0.060282</td>\n      <td>0.076829</td>\n      <td>0.325747</td>\n      <td>0.056455</td>\n      <td>0.239840</td>\n      <td>0.047217</td>\n      <td>27.680383</td>\n      <td>0.085372</td>\n      <td>...</td>\n      <td>0.045370</td>\n      <td>0.047184</td>\n      <td>0.114786</td>\n      <td>0.107574</td>\n      <td>0.100771</td>\n      <td>0.512889</td>\n      <td>0.013147</td>\n      <td>94.074203</td>\n      <td>1.0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>9155</th>\n      <td>0.045098</td>\n      <td>0.168443</td>\n      <td>0.068901</td>\n      <td>0.114206</td>\n      <td>0.328712</td>\n      <td>0.044413</td>\n      <td>0.193135</td>\n      <td>0.037093</td>\n      <td>23.489932</td>\n      <td>0.123299</td>\n      <td>...</td>\n      <td>0.048632</td>\n      <td>0.049617</td>\n      <td>0.117277</td>\n      <td>0.105903</td>\n      <td>0.097607</td>\n      <td>0.498269</td>\n      <td>0.012862</td>\n      <td>97.610233</td>\n      <td>1.0</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n<p>1421 rows × 209 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "df[(df['target']==3) | (df['target']==1)]"
   ]
  },
  {
   "source": [
    "### train test split"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(48976, 209) (2553, 209)\n"
     ]
    }
   ],
   "source": [
    "df_interictal=df[df['target']==0]\n",
    "# print(df_interictal.shape)\n",
    "# df_interictal=df_interictal.sample(frac=0.7)\n",
    "df_preictal=df[df['target']==2]\n",
    "print(df_interictal.shape, df_preictal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.049544916454811856"
      ]
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "source": [
    "2553/(2553+48976)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "14579    0\n",
       "14580    0\n",
       "14581    0\n",
       "14582    0\n",
       "14583    0\n",
       "Name: target, Length: 12188, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "df_interictal['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_interictal=np.array(df_interictal[df.columns[:-1]]).astype('float32')\n",
    "y_interictal=np.array(df_interictal['target']).astype('float32')\n",
    "X_preictal  =np.array(df_preictal[df.columns[:-1]]).astype('float32')\n",
    "y_preictal  =np.array(df_preictal['target']).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(48976, 208)\n(48976,)\n(2553, 208)\n(2553,)\n"
     ]
    }
   ],
   "source": [
    "print(X_interictal.shape)\n",
    "print(y_interictal.shape)\n",
    "print(X_preictal.shape)\n",
    "print(y_preictal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "137174"
      ]
     },
     "metadata": {},
     "execution_count": 89
    }
   ],
   "source": [
    "130304+6870"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               0         1         2         3         4         5         6  \\\n",
       "885     0.313209  0.105117  0.177755  0.170171  0.130082  0.011442  0.085478   \n",
       "886     0.361305  0.104534  0.148806  0.178307  0.115854  0.009840  0.075175   \n",
       "887     0.350512  0.105335  0.136584  0.175367  0.127451  0.011300  0.086123   \n",
       "888     0.322681  0.101829  0.152082  0.189847  0.130983  0.011281  0.084018   \n",
       "889     0.301142  0.102314  0.173153  0.207157  0.121025  0.010474  0.078348   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "149676  0.060026  0.192568  0.131846  0.142469  0.265760  0.037718  0.138473   \n",
       "149677  0.011526  0.083213  0.013058  0.018777  0.219783  0.073176  0.397635   \n",
       "149678  0.009555  0.079954  0.011768  0.014612  0.208401  0.078375  0.410033   \n",
       "149679  0.016634  0.083771  0.033295  0.038685  0.199133  0.090117  0.399899   \n",
       "149680  0.033190  0.111492  0.100169  0.139850  0.242689  0.051795  0.239182   \n",
       "\n",
       "               7            8         9  ...       199       200       201  \\\n",
       "885     0.006744    31.195422  0.185326  ...  0.135054  0.295482  0.275806   \n",
       "886     0.006179    35.477830  0.254696  ...  0.131401  0.274972  0.285203   \n",
       "887     0.007327    30.993516  0.258523  ...  0.137225  0.273114  0.272945   \n",
       "888     0.007280    30.840686  0.213205  ...  0.131797  0.291868  0.275333   \n",
       "889     0.006388    33.194468  0.230240  ...  0.131175  0.261674  0.314244   \n",
       "...          ...          ...       ...  ...       ...       ...       ...   \n",
       "149676  0.031140   378.386978  0.021143  ...  0.153421  0.005989  0.014741   \n",
       "149677  0.182831  3452.284012  0.004761  ...  0.137901  0.015380  0.035846   \n",
       "149678  0.187302  4265.836601  0.006300  ...  0.171916  0.029890  0.068148   \n",
       "149679  0.138465   902.970531  0.015999  ...  0.172627  0.029499  0.076296   \n",
       "149680  0.081633   210.204870  0.015964  ...  0.154085  0.021617  0.062482   \n",
       "\n",
       "             202       203       204       205          206  207  target  \n",
       "885     0.049864  0.007605  0.049843  0.004499    24.849719  1.0       2  \n",
       "886     0.052202  0.006579  0.043109  0.003889    27.723220  1.0       2  \n",
       "887     0.057310  0.007824  0.049630  0.004442    23.797804  1.0       2  \n",
       "888     0.058885  0.008209  0.052058  0.004627    22.406452  1.0       2  \n",
       "889     0.050905  0.006702  0.046090  0.004024    26.524375  1.0       2  \n",
       "...          ...       ...       ...       ...          ...  ...     ...  \n",
       "149676  0.292584  0.062299  0.333739  0.126612  1734.162379  9.0       2  \n",
       "149677  0.280160  0.060160  0.309436  0.136690  1060.737877  9.0       2  \n",
       "149678  0.327419  0.048095  0.245393  0.073114   764.756033  9.0       2  \n",
       "149679  0.306140  0.056033  0.266259  0.068919   560.460805  9.0       2  \n",
       "149680  0.323918  0.062960  0.288750  0.064985   425.806400  9.0       2  \n",
       "\n",
       "[6869 rows x 209 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>199</th>\n      <th>200</th>\n      <th>201</th>\n      <th>202</th>\n      <th>203</th>\n      <th>204</th>\n      <th>205</th>\n      <th>206</th>\n      <th>207</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>885</th>\n      <td>0.313209</td>\n      <td>0.105117</td>\n      <td>0.177755</td>\n      <td>0.170171</td>\n      <td>0.130082</td>\n      <td>0.011442</td>\n      <td>0.085478</td>\n      <td>0.006744</td>\n      <td>31.195422</td>\n      <td>0.185326</td>\n      <td>...</td>\n      <td>0.135054</td>\n      <td>0.295482</td>\n      <td>0.275806</td>\n      <td>0.049864</td>\n      <td>0.007605</td>\n      <td>0.049843</td>\n      <td>0.004499</td>\n      <td>24.849719</td>\n      <td>1.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>886</th>\n      <td>0.361305</td>\n      <td>0.104534</td>\n      <td>0.148806</td>\n      <td>0.178307</td>\n      <td>0.115854</td>\n      <td>0.009840</td>\n      <td>0.075175</td>\n      <td>0.006179</td>\n      <td>35.477830</td>\n      <td>0.254696</td>\n      <td>...</td>\n      <td>0.131401</td>\n      <td>0.274972</td>\n      <td>0.285203</td>\n      <td>0.052202</td>\n      <td>0.006579</td>\n      <td>0.043109</td>\n      <td>0.003889</td>\n      <td>27.723220</td>\n      <td>1.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>887</th>\n      <td>0.350512</td>\n      <td>0.105335</td>\n      <td>0.136584</td>\n      <td>0.175367</td>\n      <td>0.127451</td>\n      <td>0.011300</td>\n      <td>0.086123</td>\n      <td>0.007327</td>\n      <td>30.993516</td>\n      <td>0.258523</td>\n      <td>...</td>\n      <td>0.137225</td>\n      <td>0.273114</td>\n      <td>0.272945</td>\n      <td>0.057310</td>\n      <td>0.007824</td>\n      <td>0.049630</td>\n      <td>0.004442</td>\n      <td>23.797804</td>\n      <td>1.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>888</th>\n      <td>0.322681</td>\n      <td>0.101829</td>\n      <td>0.152082</td>\n      <td>0.189847</td>\n      <td>0.130983</td>\n      <td>0.011281</td>\n      <td>0.084018</td>\n      <td>0.007280</td>\n      <td>30.840686</td>\n      <td>0.213205</td>\n      <td>...</td>\n      <td>0.131797</td>\n      <td>0.291868</td>\n      <td>0.275333</td>\n      <td>0.058885</td>\n      <td>0.008209</td>\n      <td>0.052058</td>\n      <td>0.004627</td>\n      <td>22.406452</td>\n      <td>1.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>889</th>\n      <td>0.301142</td>\n      <td>0.102314</td>\n      <td>0.173153</td>\n      <td>0.207157</td>\n      <td>0.121025</td>\n      <td>0.010474</td>\n      <td>0.078348</td>\n      <td>0.006388</td>\n      <td>33.194468</td>\n      <td>0.230240</td>\n      <td>...</td>\n      <td>0.131175</td>\n      <td>0.261674</td>\n      <td>0.314244</td>\n      <td>0.050905</td>\n      <td>0.006702</td>\n      <td>0.046090</td>\n      <td>0.004024</td>\n      <td>26.524375</td>\n      <td>1.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>149676</th>\n      <td>0.060026</td>\n      <td>0.192568</td>\n      <td>0.131846</td>\n      <td>0.142469</td>\n      <td>0.265760</td>\n      <td>0.037718</td>\n      <td>0.138473</td>\n      <td>0.031140</td>\n      <td>378.386978</td>\n      <td>0.021143</td>\n      <td>...</td>\n      <td>0.153421</td>\n      <td>0.005989</td>\n      <td>0.014741</td>\n      <td>0.292584</td>\n      <td>0.062299</td>\n      <td>0.333739</td>\n      <td>0.126612</td>\n      <td>1734.162379</td>\n      <td>9.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>149677</th>\n      <td>0.011526</td>\n      <td>0.083213</td>\n      <td>0.013058</td>\n      <td>0.018777</td>\n      <td>0.219783</td>\n      <td>0.073176</td>\n      <td>0.397635</td>\n      <td>0.182831</td>\n      <td>3452.284012</td>\n      <td>0.004761</td>\n      <td>...</td>\n      <td>0.137901</td>\n      <td>0.015380</td>\n      <td>0.035846</td>\n      <td>0.280160</td>\n      <td>0.060160</td>\n      <td>0.309436</td>\n      <td>0.136690</td>\n      <td>1060.737877</td>\n      <td>9.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>149678</th>\n      <td>0.009555</td>\n      <td>0.079954</td>\n      <td>0.011768</td>\n      <td>0.014612</td>\n      <td>0.208401</td>\n      <td>0.078375</td>\n      <td>0.410033</td>\n      <td>0.187302</td>\n      <td>4265.836601</td>\n      <td>0.006300</td>\n      <td>...</td>\n      <td>0.171916</td>\n      <td>0.029890</td>\n      <td>0.068148</td>\n      <td>0.327419</td>\n      <td>0.048095</td>\n      <td>0.245393</td>\n      <td>0.073114</td>\n      <td>764.756033</td>\n      <td>9.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>149679</th>\n      <td>0.016634</td>\n      <td>0.083771</td>\n      <td>0.033295</td>\n      <td>0.038685</td>\n      <td>0.199133</td>\n      <td>0.090117</td>\n      <td>0.399899</td>\n      <td>0.138465</td>\n      <td>902.970531</td>\n      <td>0.015999</td>\n      <td>...</td>\n      <td>0.172627</td>\n      <td>0.029499</td>\n      <td>0.076296</td>\n      <td>0.306140</td>\n      <td>0.056033</td>\n      <td>0.266259</td>\n      <td>0.068919</td>\n      <td>560.460805</td>\n      <td>9.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>149680</th>\n      <td>0.033190</td>\n      <td>0.111492</td>\n      <td>0.100169</td>\n      <td>0.139850</td>\n      <td>0.242689</td>\n      <td>0.051795</td>\n      <td>0.239182</td>\n      <td>0.081633</td>\n      <td>210.204870</td>\n      <td>0.015964</td>\n      <td>...</td>\n      <td>0.154085</td>\n      <td>0.021617</td>\n      <td>0.062482</td>\n      <td>0.323918</td>\n      <td>0.062960</td>\n      <td>0.288750</td>\n      <td>0.064985</td>\n      <td>425.806400</td>\n      <td>9.0</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>6869 rows × 209 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 90
    }
   ],
   "source": [
    "df_preictal[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_interictal_train, X_interictal_test, y_interictal_train, y_interictal_test =train_test_split(X_interictal,y_interictal,test_size=0.1, random_state=42)\n",
    "X_preictal_train, X_preictal_test, y_preictal_train, y_preictal_test=train_test_split(X_preictal, y_preictal,test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate((X_interictal_train, X_preictal_train))\n",
    "X_test = np.concatenate((X_interictal_test, X_preictal_test))\n",
    "y_train = np.concatenate((y_interictal_train, y_preictal_train))\n",
    "y_test = np.concatenate((y_interictal_test, y_preictal_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(46375, 208)\n(5154, 208)\n(46375,)\n(5154,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "source": [
    "### Normalization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[5.06899767e-02, 2.06566319e-01, 2.44740620e-02, ...,\n",
       "        3.16168010e-01, 8.29013061e-07, 1.00000000e+00],\n",
       "       [2.38289069e-02, 2.64799237e-01, 1.16495766e-01, ...,\n",
       "        1.51608899e-01, 2.98875057e-06, 0.00000000e+00],\n",
       "       [1.77743211e-02, 1.85866445e-01, 1.43353671e-01, ...,\n",
       "        1.70185298e-01, 9.69898610e-06, 6.66666627e-01],\n",
       "       ...,\n",
       "       [2.15109922e-02, 9.67502445e-02, 1.10558691e-02, ...,\n",
       "        4.12113339e-01, 1.13175914e-03, 1.00000000e+00],\n",
       "       [6.81196852e-03, 6.83366656e-02, 3.92035069e-03, ...,\n",
       "        4.36358184e-01, 4.70467021e-05, 6.66666627e-01],\n",
       "       [4.16661575e-02, 2.63042718e-01, 1.29583791e-01, ...,\n",
       "        1.59748152e-01, 5.48839807e-06, 3.33333343e-01]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# scaler = MinMaxScaler()\n",
    "# scaler.fit(X_train)\n",
    "# scaler.transform(X_train)\n",
    "# scaler.fit(X_test)\n",
    "# scaler.transform(X_test)"
   ]
  },
  {
   "source": [
    "### training the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "14:27:52\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "before = datetime.now()\n",
    "\n",
    "before_time =before.strftime(\"%H:%M:%S\")\n",
    "print(before_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_dict={0:0.1, 2:1.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "**SVM Results:**\nTraining Accuracy: 68%\nTesting Accuracy: 70%\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(class_weight=weight_dict)\n",
    "clf.fit(X_train, y_train)\n",
    "trainAcc = clf.score(X_train, y_train)\n",
    "testAcc = clf.score(X_test, y_test)\n",
    "print(\"**SVM Results:**\")\n",
    "print(\"Training Accuracy: %d\"%(trainAcc*100)+\"%\")\n",
    "print(\"Testing Accuracy: %d\"%(testAcc *100)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "15:45:47\n"
     ]
    }
   ],
   "source": [
    "after = datetime.now()\n",
    "\n",
    "after_time =after.strftime(\"%H:%M:%S\")\n",
    "print(after_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "saving new model\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['my_models/SVM_blanced_chb04.pkl']"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "    # estimator = joblib.load(\"/my_models/%s.pkl\"%dataset_name)\n",
    "    # print \"using trained model\"\n",
    "\n",
    "print (\"saving new model\")\n",
    "joblib.dump(clf,\"my_models/SVM_blanced_chb04.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_clf = joblib.load(\"my_models/SVM_blanced_chb04.pkl\")\n",
    "y_pred=loaded_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'break_ties': False,\n",
       " 'cache_size': 200,\n",
       " 'class_weight': 'balanced',\n",
       " 'coef0': 0.0,\n",
       " 'decision_function_shape': 'ovr',\n",
       " 'degree': 3,\n",
       " 'gamma': 'scale',\n",
       " 'kernel': 'rbf',\n",
       " 'max_iter': -1,\n",
       " 'probability': False,\n",
       " 'random_state': None,\n",
       " 'shrinking': True,\n",
       " 'tol': 0.001,\n",
       " 'verbose': False}"
      ]
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "loaded_clf.get_params(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TN:4844, FP:54, FN:240, TP:16\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = sklearn.metrics.confusion_matrix(y_test, y_pred).ravel()\n",
    "print(\"TN:{}, FP:{}, FN:{}, TP:{}\".format(tn, fp, fn, tp))"
   ]
  },
  {
   "source": [
    "### grid search"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "balance = [{0:10,2:1}, {0:1,2:1}, {0:1,2:10}, {0:1,2:50}, {0:1,2:100}]\n",
    "param_grid = dict(class_weight=balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=1, random_state=1)\n",
    "grid = GridSearchCV(estimator=clf, param_grid=param_grid, n_jobs=-1, cv=cv, scoring='roc_auc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}